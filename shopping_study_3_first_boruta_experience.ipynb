{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "from time import time\n",
    "from IPython.display import display \n",
    "%matplotlib inline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "data = pd.read_csv('online_shoppers_intention.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up Sampling The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sample_minority_class():\n",
    "    # Entries of the both minority and majority classes\n",
    "    data_majority = data.loc[data['Revenue'] == 0.0]\n",
    "    data_minority = data.loc[data['Revenue'] == 1.0]\n",
    "    \n",
    "    print(\"data_majority: {0} @ data_minority: {1}\".format(len(data_majority), len(data_minority)))\n",
    "    \n",
    "    #populates the minority portion of the samples up to the size of majority portion\n",
    "    data_minority_up_sampled = resample(data_minority, \n",
    "                                     replace=True,\n",
    "                                     n_samples=len(data_majority),\n",
    "                                     random_state=142)\n",
    "    \n",
    "    # Combine majority class with upsampled minority class\n",
    "    data_up_sampled = pd.concat([data_majority, data_minority_up_sampled])\n",
    "    \n",
    "    # Display new class counts\n",
    "    print(data_up_sampled.Revenue.value_counts())\n",
    "    \n",
    "    X_up_sampled = np.array(data_up_sampled.drop(['Revenue'], 1).astype(float))\n",
    "    y_up_sampled = np.array(data_up_sampled['Revenue']).astype(float)\n",
    "    X_train_up_sampled, X_test_up_sampled, y_train_up_sampled, y_test_up_sampled = train_test_split(X_up_sampled, y_up_sampled, random_state=11)\n",
    "    \n",
    "    return X_train_up_sampled, X_test_up_sampled, y_train_up_sampled, y_test_up_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink_dataset(data, ratio):\n",
    "    values_set = set(data.Revenue)\n",
    "    \n",
    "    data_shrinked = data\n",
    "    data_shrinked = data_shrinked[0:0]\n",
    "    \n",
    "    for v in values_set:\n",
    "        cr_class_entries = data_majority = data.loc[data['Revenue'] == v]\n",
    "\n",
    "        original_length = len(cr_class_entries)\n",
    "        cr_class_entries_shrinked = resample(cr_class_entries, \n",
    "                                         replace=True,\n",
    "                                         n_samples=int(len(cr_class_entries)*ratio),\n",
    "                                         random_state=142)\n",
    "        \n",
    "        print(\"cr_class_entries > {0} >>> {1} @ cr_class_entries_shrinked: {2}\".format(v, original_length, len(cr_class_entries_shrinked)))\n",
    "\n",
    "        # Combine majority class with upsampled minority class\n",
    "        data_shrinked = pd.concat([data_shrinked, cr_class_entries_shrinked])\n",
    "    \n",
    "    # Display new class counts\n",
    "    print(data_shrinked.Revenue.value_counts())\n",
    "    \n",
    "    return data_shrinked\n",
    "\n",
    "#data = shrink_dataset(data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    10422\n",
       "True      1908\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Revenue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_majority: 10422 @ data_minority: 1908\n",
      "1.0    10422\n",
      "0.0    10422\n",
      "Name: Revenue, dtype: int64\n",
      "\n",
      "Accuracy Score: 0.9650738821723278\n",
      "Precision Score: 0.9423144565599718\n",
      "Recall Score: 0.9933259176863182\n",
      "F-Beta Score: 0.9520932546733953\n",
      "\n",
      "time elapsed: 0.3673708438873291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "data['Month'] =  ohe.fit_transform(data[['Month']])\n",
    "data['VisitorType'] =  ohe.fit_transform(data[['VisitorType']])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "\n",
    "\n",
    "X = np.array(data.drop(['Revenue'], 1).astype(float))\n",
    "y = np.array(data['Revenue']).astype(float)\n",
    "\n",
    "\n",
    "time0 = time()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = up_sample_minority_class()\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy Score: {0}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"Precision Score: {0}\".format(precision_score(y_test, predictions)))\n",
    "print(\"Recall Score: {0}\".format(recall_score(y_test, predictions)))\n",
    "print(\"F-Beta Score: {0}\".format(fbeta_score(y_test, predictions, beta=0.5)))\n",
    "\n",
    "\n",
    "\n",
    "time1 = time()\n",
    "diff = time1-time0\n",
    "print(\"\\ntime elapsed: {0}\\n\".format(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search with All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2165961ae5ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step 1\\n------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "print(\"Step 1\\n------\")\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "\n",
    "# Create the parameters list \n",
    "parameters =  {\n",
    " 'max_depth': [10,20,30,40],\n",
    " 'max_features': [2, 3],\n",
    " 'min_samples_leaf': [3, 4, 5],\n",
    " 'min_samples_split': [8, 10, 12],\n",
    " 'n_estimators': [50,100,150]}\n",
    "\n",
    "\n",
    "\n",
    "# Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "print(\"Step 2\\n------\")\n",
    "\n",
    "# Perform grid search on the classifier \n",
    "grid_obj = GridSearchCV(estimator=clf, param_grid=parameters, scoring=scorer)\n",
    "\n",
    "\n",
    "print(\"Step 3\\n------\")\n",
    "\n",
    "# Fit the grid search object to the training data \n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Step 4\\n------\")\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Step 5\\n------\")\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Step 6\\n------\")\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Total Time Elapsed: {0} seconds\\n------\".format((end_time-start_time)))\n",
    "print(\"Accuracy score on testing data {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\ngrid_fit.best_params_: {0}\".format(grid_fit.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection via Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t17\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t1\n",
      "Rejected: \t11\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t1\n",
      "Rejected: \t11\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t1\n",
      "Rejected: \t11\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t5\n",
      "Tentative: \t1\n",
      "Rejected: \t11\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t6\n",
      "Tentative: \t0\n",
      "Rejected: \t11\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t6\n",
      "Tentative: \t0\n",
      "Rejected: \t11\n",
      "feat_selector.ranking_: [ 2  1  6  4  1  1  1  1  1 11 12  8  7  5  3  9 10]\n",
      "data_majority: 10422 @ data_minority: 1908\n",
      "1.0    10422\n",
      "0.0    10422\n",
      "Name: Revenue, dtype: int64\n",
      "\n",
      "Accuracy Score: 0.9644981769334101\n",
      "Precision Score: 0.9397759103641457\n",
      "Recall Score: 0.9951798294401186\n",
      "F-Beta Score: 0.9503576233977763\n",
      "\n",
      "time elapsed: 0.3901536464691162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy \n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(clf, n_estimators='auto', verbose=2, alpha=0.20)\n",
    " \n",
    "# find all relevant features\n",
    "feat_selector.fit(X, y)\n",
    " \n",
    "# check selected features\n",
    "feat_selector.support_\n",
    " \n",
    "# check ranking of features\n",
    "feat_selector.ranking_\n",
    "\n",
    "print(\"feat_selector.ranking_: {}\".format(feat_selector.ranking_))\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(data.drop(['Revenue'], 1).astype(float))\n",
    "y = np.array(data['Revenue']).astype(float)\n",
    "\n",
    "\n",
    "X = feat_selector.transform(X)\n",
    "\n",
    "\n",
    "time0 = time()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = up_sample_minority_class()\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy Score: {0}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"Precision Score: {0}\".format(precision_score(y_test, predictions)))\n",
    "print(\"Recall Score: {0}\".format(recall_score(y_test, predictions)))\n",
    "print(\"F-Beta Score: {0}\".format(fbeta_score(y_test, predictions, beta=0.5)))\n",
    "\n",
    "\n",
    "\n",
    "time1 = time()\n",
    "diff = time1-time0\n",
    "print(\"\\ntime elapsed: {0}\\n\".format(diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch with Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "------\n",
      "Step 2\n",
      "------\n",
      "Step 3\n",
      "------\n",
      "Step 4\n",
      "------\n",
      "Step 5\n",
      "------\n",
      "Step 6\n",
      "------\n",
      "Optimized model With Best Features\n",
      "------\n",
      "Total Time Elapsed: 97.52665114402771 seconds\n",
      "------\n",
      "Accuracy score on testing data 0.9639\n",
      "F-score on testing data: 0.9507\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.9294\n",
      "Final F-score on the testing data: 0.9228\n",
      "\n",
      "grid_fit.best_params_: {'max_depth': 25, 'max_features': 4, 'min_samples_leaf': 4, 'min_samples_split': 11, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "print(\"Step 1\\n------\")\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state = 42, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Create the parameters list \n",
    "parameters =  {\n",
    "    'max_depth': [15,20,25],\n",
    "    'max_features': [3, 4],\n",
    "    'min_samples_leaf': [4],\n",
    "    'min_samples_split': [11, 12, 13],\n",
    "    'n_estimators': [25,50,75]}\n",
    "\n",
    "\n",
    "\n",
    "# Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "print(\"Step 2\\n------\")\n",
    "\n",
    "# Perform grid search on the classifier \n",
    "grid_obj = GridSearchCV(estimator=clf, param_grid=parameters, scoring=scorer)\n",
    "\n",
    "\n",
    "print(\"Step 3\\n------\")\n",
    "\n",
    "# Fit the grid search object to the training data \n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Step 4\\n------\")\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Step 5\\n------\")\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Step 6\\n------\")\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Optimized model With Best Features\\n------\")\n",
    "print(\"Total Time Elapsed: {0} seconds\\n------\".format((end_time-start_time)))\n",
    "print(\"Accuracy score on testing data {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\ngrid_fit.best_params_: {0}\".format(grid_fit.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative               int64\n",
       "Administrative_Duration    float64\n",
       "Informational                int64\n",
       "Informational_Duration     float64\n",
       "ProductRelated               int64\n",
       "ProductRelated_Duration    float64\n",
       "BounceRates                float64\n",
       "ExitRates                  float64\n",
       "PageValues                 float64\n",
       "SpecialDay                 float64\n",
       "Month                       object\n",
       "OperatingSystems             int64\n",
       "Browser                      int64\n",
       "Region                       int64\n",
       "TrafficType                  int64\n",
       "VisitorType                 object\n",
       "Weekend                       bool\n",
       "Revenue                       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0             0.0                      0.0            0.0   \n",
       "1             0.0                      0.0            0.0   \n",
       "2             0.0                      0.0            0.0   \n",
       "3             0.0                      0.0            0.0   \n",
       "4             0.0                      0.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0        0.001418                 0.000000   \n",
       "1                     0.0        0.002837                 0.001000   \n",
       "2                     0.0        0.001418                 0.000000   \n",
       "3                     0.0        0.002837                 0.000042   \n",
       "4                     0.0        0.014184                 0.009809   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  Month  OperatingSystems  \\\n",
       "0         1.00       1.00         0.0         0.0    0.0          0.000000   \n",
       "1         0.00       0.50         0.0         0.0    0.0          0.142857   \n",
       "2         1.00       1.00         0.0         0.0    0.0          0.428571   \n",
       "3         0.25       0.70         0.0         0.0    0.0          0.285714   \n",
       "4         0.10       0.25         0.0         0.0    0.0          0.285714   \n",
       "\n",
       "    Browser  Region  TrafficType  VisitorType  Weekend  Revenue  \n",
       "0  0.000000   0.000     0.000000          0.0      0.0      0.0  \n",
       "1  0.083333   0.000     0.052632          0.0      0.0      0.0  \n",
       "2  0.000000   1.000     0.105263          0.0      0.0      0.0  \n",
       "3  0.083333   0.125     0.157895          0.0      0.0      0.0  \n",
       "4  0.166667   0.000     0.157895          0.0      1.0      0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "data['Month'] =  ohe.fit_transform(data[['Month']])\n",
    "data['VisitorType'] =  ohe.fit_transform(data[['VisitorType']])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "\n",
    "X = np.array(data.drop(['Revenue'], 1).astype(float))\n",
    "y = np.array(data['Revenue']).astype(float)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11)\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training And Eveluation PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, fbeta_score\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data \n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start \n",
    "    \n",
    "    # Get the predictions on the test set\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "    \n",
    "    # Compute accuracy on the first 300 training samples \n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "    \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute F-score on the the first 300 training samples\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, beta=0.5)\n",
    "    \n",
    "    # Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta=0.5)\n",
    "    \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "    \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier trained on 92 samples.\n",
      "RandomForestClassifier trained on 924 samples.\n",
      "RandomForestClassifier trained on 9247 samples.\n",
      "GaussianNB trained on 92 samples.\n",
      "GaussianNB trained on 924 samples.\n",
      "GaussianNB trained on 9247 samples.\n",
      "SVC trained on 92 samples.\n",
      "SVC trained on 924 samples.\n",
      "SVC trained on 9247 samples.\n",
      "DecisionTreeClassifier trained on 92 samples.\n",
      "DecisionTreeClassifier trained on 924 samples.\n",
      "DecisionTreeClassifier trained on 9247 samples.\n",
      "KNeighborsClassifier trained on 92 samples.\n",
      "KNeighborsClassifier trained on 924 samples.\n",
      "KNeighborsClassifier trained on 9247 samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier': {0: {'train_time': 0.1080169677734375,\n",
       "   'pred_time': 0.026578664779663086,\n",
       "   'acc_train': 0.9333333333333333,\n",
       "   'acc_test': 0.8874472915990917,\n",
       "   'f_train': 0.8675799086757991,\n",
       "   'f_test': 0.6567915036333147},\n",
       "  1: {'train_time': 0.13169550895690918,\n",
       "   'pred_time': 0.03311634063720703,\n",
       "   'acc_train': 1.0,\n",
       "   'acc_test': 0.8913396042815439,\n",
       "   'f_train': 1.0,\n",
       "   'f_test': 0.6720867208672088},\n",
       "  2: {'train_time': 0.8086287975311279,\n",
       "   'pred_time': 0.04942035675048828,\n",
       "   'acc_train': 1.0,\n",
       "   'acc_test': 0.8984755108660396,\n",
       "   'f_train': 1.0,\n",
       "   'f_test': 0.6999471737982039}},\n",
       " 'GaussianNB': {0: {'train_time': 0.0005707740783691406,\n",
       "   'pred_time': 0.0023827552795410156,\n",
       "   'acc_train': 0.84,\n",
       "   'acc_test': 0.8387933830684399,\n",
       "   'f_train': 0.5598455598455597,\n",
       "   'f_test': 0.4617752693689071},\n",
       "  1: {'train_time': 0.0007288455963134766,\n",
       "   'pred_time': 0.0006897449493408203,\n",
       "   'acc_train': 0.7366666666666667,\n",
       "   'acc_test': 0.761271488809601,\n",
       "   'f_train': 0.42462845010615713,\n",
       "   'f_test': 0.4062126642771804},\n",
       "  2: {'train_time': 0.0029745101928710938,\n",
       "   'pred_time': 0.0009951591491699219,\n",
       "   'acc_train': 0.7733333333333333,\n",
       "   'acc_test': 0.784625364904314,\n",
       "   'f_train': 0.4740406320541761,\n",
       "   'f_test': 0.4264507422402159}},\n",
       " 'SVC': {0: {'train_time': 0.0009922981262207031,\n",
       "   'pred_time': 0.005975484848022461,\n",
       "   'acc_train': 0.8233333333333334,\n",
       "   'acc_test': 0.843658773921505,\n",
       "   'f_train': 0.15873015873015872,\n",
       "   'f_test': 0.10242085661080075},\n",
       "  1: {'train_time': 0.01726818084716797,\n",
       "   'pred_time': 0.036971330642700195,\n",
       "   'acc_train': 0.8633333333333333,\n",
       "   'acc_test': 0.8520921180668181,\n",
       "   'f_train': 0.6302521008403361,\n",
       "   'f_test': 0.3120464441219158},\n",
       "  2: {'train_time': 1.326747179031372,\n",
       "   'pred_time': 0.26405811309814453,\n",
       "   'acc_train': 0.88,\n",
       "   'acc_test': 0.8734998378203049,\n",
       "   'f_train': 0.7055214723926381,\n",
       "   'f_test': 0.5813953488372093}},\n",
       " 'DecisionTreeClassifier': {0: {'train_time': 0.0005710124969482422,\n",
       "   'pred_time': 0.0003256797790527344,\n",
       "   'acc_train': 0.9166666666666666,\n",
       "   'acc_test': 0.8589036652611093,\n",
       "   'f_train': 0.7706093189964158,\n",
       "   'f_test': 0.5635130041462495},\n",
       "  1: {'train_time': 0.0034422874450683594,\n",
       "   'pred_time': 0.0003402233123779297,\n",
       "   'acc_train': 1.0,\n",
       "   'acc_test': 0.8559844307492702,\n",
       "   'f_train': 1.0,\n",
       "   'f_test': 0.5506607929515418},\n",
       "  2: {'train_time': 0.04317045211791992,\n",
       "   'pred_time': 0.0005125999450683594,\n",
       "   'acc_train': 1.0,\n",
       "   'acc_test': 0.8702562439182614,\n",
       "   'f_train': 1.0,\n",
       "   'f_test': 0.594616311771796}},\n",
       " 'KNeighborsClassifier': {0: {'train_time': 0.0008323192596435547,\n",
       "   'pred_time': 0.07691335678100586,\n",
       "   'acc_train': 0.85,\n",
       "   'acc_test': 0.8313331170937399,\n",
       "   'f_train': 0.546218487394958,\n",
       "   'f_test': 0.255653883972468},\n",
       "  1: {'train_time': 0.0012307167053222656,\n",
       "   'pred_time': 0.13154292106628418,\n",
       "   'acc_train': 0.8366666666666667,\n",
       "   'acc_test': 0.8446318520921181,\n",
       "   'f_train': 0.4022988505747126,\n",
       "   'f_test': 0.22156573116691286},\n",
       "  2: {'train_time': 0.02709341049194336,\n",
       "   'pred_time': 0.43514490127563477,\n",
       "   'acc_train': 0.8733333333333333,\n",
       "   'acc_test': 0.8572818683100876,\n",
       "   'f_train': 0.6802721088435374,\n",
       "   'f_test': 0.4481369587109768}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the three models\n",
    "random_state = 55\n",
    "\n",
    "clf_A = RandomForestClassifier(random_state=random_state)\n",
    "clf_B = GaussianNB()\n",
    "clf_C = SVC(random_state=random_state)\n",
    "clf_D = DecisionTreeClassifier()\n",
    "clf_E = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int(len(y_train)/10)\n",
    "samples_1 = int(len(y_train)/100)\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C, clf_D, clf_E]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10,   samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999471737982039"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[clf_A.__class__.__name__][2]['f_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Score: 0.9045095706715691\n",
      "Test Set Score: 0.8978267920856309\n",
      "Cross Validation Score: 0.8896188158961882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0             0.0                      0.0            0.0   \n",
       "1             0.0                      0.0            0.0   \n",
       "2             0.0                      0.0            0.0   \n",
       "3             0.0                      0.0            0.0   \n",
       "4             0.0                      0.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0        0.001418                 0.000000   \n",
       "1                     0.0        0.002837                 0.001000   \n",
       "2                     0.0        0.001418                 0.000000   \n",
       "3                     0.0        0.002837                 0.000042   \n",
       "4                     0.0        0.014184                 0.009809   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  Month  OperatingSystems  \\\n",
       "0         1.00       1.00         0.0         0.0    0.0          0.000000   \n",
       "1         0.00       0.50         0.0         0.0    0.0          0.142857   \n",
       "2         1.00       1.00         0.0         0.0    0.0          0.428571   \n",
       "3         0.25       0.70         0.0         0.0    0.0          0.285714   \n",
       "4         0.10       0.25         0.0         0.0    0.0          0.285714   \n",
       "\n",
       "    Browser  Region  TrafficType  VisitorType  Weekend  Revenue  \n",
       "0  0.000000   0.000     0.000000          0.0      0.0      0.0  \n",
       "1  0.083333   0.000     0.052632          0.0      0.0      0.0  \n",
       "2  0.000000   1.000     0.105263          0.0      0.0      0.0  \n",
       "3  0.083333   0.125     0.157895          0.0      0.0      0.0  \n",
       "4  0.166667   0.000     0.157895          0.0      1.0      0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5).fit(X_train, y_train)\n",
    "\n",
    "print(\"Train Set Score: {0}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Test Set Score: {0}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Cross Validation Score: {0}\".format(np.mean(cross_val_score(clf,X,y))))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "------\n",
      "Step 2\n",
      "------\n",
      "Step 3\n",
      "------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-20c13286461d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Fit the grid search object to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mgrid_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "print(\"Step 1\\n------\")\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "\n",
    "# Create the parameters list \n",
    "parameters =  {\n",
    "    'max_depth': [15,20,25],\n",
    "    'max_features': [3, 4],\n",
    "    'min_samples_leaf': [4],\n",
    "    'min_samples_split': [11, 12, 13],\n",
    "    'n_estimators': [25,50,75]}\n",
    "\n",
    "\n",
    "\n",
    "# Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "print(\"Step 2\\n------\")\n",
    "\n",
    "# Perform grid search on the classifier \n",
    "grid_obj = GridSearchCV(estimator=clf, param_grid=parameters, scoring=scorer)\n",
    "\n",
    "\n",
    "print(\"Step 3\\n------\")\n",
    "\n",
    "# Fit the grid search object to the training data \n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Step 4\\n------\")\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Step 5\\n------\")\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Step 6\\n------\")\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Total Time Elapsed: {0} seconds\\n------\".format((end_time-start_time)))\n",
    "print(\"Accuracy score on testing data {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "print(\"\\ngrid_fit.best_params_: {0}\".format(grid_fit.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8952319169639961\n",
      "Precision Score: 0.7575757575757576\n",
      "Recall Score: 0.5070993914807302\n",
      "F-Beta Score: 0.6894649751792609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=20, max_features=3\n",
    "                             , min_samples_leaf=4, min_samples_split=12, n_estimators=50).fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score: {0}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"Precision Score: {0}\".format(precision_score(y_test, predictions)))\n",
    "print(\"Recall Score: {0}\".format(recall_score(y_test, predictions)))\n",
    "print(\"F-Beta Score: {0}\".format(fbeta_score(y_test, predictions, beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(clf, X_test, y_test):\n",
    "    true_positive = 0\n",
    "    true_negative = 0 \n",
    "    false_positive = 0 \n",
    "    false_negative = 0\n",
    "    \n",
    "    y_test_list = y_test.tolist()\n",
    "\n",
    "    all_successful_samples = 0\n",
    "    all_positive_predictions = 0\n",
    "    true_positives = 0\n",
    "\n",
    "    predicts = clf.predict(X_test)\n",
    "\n",
    "    for i in range(0, len(predicts)):\n",
    "        if y_test_list[i] == 1:\n",
    "            if predicts[i] == 1:\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        else:\n",
    "            if predicts[i] == 1:\n",
    "                false_positive += 1\n",
    "            else:\n",
    "                true_negative += 1\n",
    "    \n",
    "    return true_positive, true_negative, false_positive, false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(clf, X_test, y_test):\n",
    "    true_positive, true_negative, false_positive, false_negative = get_confusion_matrix(clf, X_test, y_test)\n",
    "    \n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    \n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "    precision = (true_positive) / (true_positive + false_positive)\n",
    "    recall = (true_positive) / (true_positive + false_negative)\n",
    "    \n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8952319169639961\n",
      "precision: 0.7575757575757576\n",
      "recall: 0.5070993914807302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall = get_performance_metrics(clf, X_test, y_test)\n",
    "print(\"accuracy: {0}\\nprecision: {1}\\nrecall: {2}\\n\"\n",
    "      .format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    10422\n",
       "1.0     1908\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Revenue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.042663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075177</td>\n",
       "      <td>0.027883</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.145153</td>\n",
       "      <td>0.033839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "12325        0.111111                 0.042663            0.0   \n",
       "12326        0.000000                 0.000000            0.0   \n",
       "12327        0.000000                 0.000000            0.0   \n",
       "12328        0.148148                 0.022067            0.0   \n",
       "12329        0.000000                 0.000000            0.0   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "12325                     0.0        0.075177                 0.027883   \n",
       "12326                     0.0        0.007092                 0.007280   \n",
       "12327                     0.0        0.008511                 0.002880   \n",
       "12328                     0.0        0.021277                 0.005408   \n",
       "12329                     0.0        0.004255                 0.000332   \n",
       "\n",
       "       BounceRates  ExitRates  PageValues  SpecialDay  Month  \\\n",
       "12325     0.035714   0.145153    0.033839         0.0    0.0   \n",
       "12326     0.000000   0.106667    0.000000         0.0    0.0   \n",
       "12327     0.416667   0.433333    0.000000         0.0    0.0   \n",
       "12328     0.000000   0.105263    0.000000         0.0    0.0   \n",
       "12329     0.000000   0.333333    0.000000         0.0    0.0   \n",
       "\n",
       "       OperatingSystems   Browser  Region  TrafficType  VisitorType  Weekend  \\\n",
       "12325          0.428571  0.416667    0.00     0.000000          0.0      1.0   \n",
       "12326          0.285714  0.083333    0.00     0.368421          0.0      1.0   \n",
       "12327          0.285714  0.083333    0.00     0.631579          0.0      1.0   \n",
       "12328          0.142857  0.083333    0.25     0.526316          0.0      0.0   \n",
       "12329          0.285714  0.083333    0.00     0.052632          1.0      1.0   \n",
       "\n",
       "       Revenue  \n",
       "12325      0.0  \n",
       "12326      0.0  \n",
       "12327      0.0  \n",
       "12328      0.0  \n",
       "12329      0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Down Sampling Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample_minority_class():\n",
    "    # Entries of the both minority and majority classes\n",
    "    data_majority = data.loc[data['Revenue'] == 0.0]\n",
    "    data_minority = data.loc[data['Revenue'] == 1.0]\n",
    "    \n",
    "    print(\"data_majority: {0} @ data_minority: {1}\".format(len(data_majority), len(data_minority)))\n",
    "    \n",
    "    #populates the majority portion of the samples down to the number of minority portion\n",
    "    data_majority_down_sampled = resample(data_majority, \n",
    "                                     replace=True,\n",
    "                                     n_samples=len(data_minority),\n",
    "                                     random_state=142)\n",
    "    \n",
    "    # Combine minority class with downsampled majority class\n",
    "    data_down_sampled = pd.concat([data_minority, data_majority_down_sampled])\n",
    "    \n",
    "    \n",
    "    # Display new class distrubution\n",
    "    print(\"After Down-sampling:\\n{0}\".format(data_down_sampled.Revenue.value_counts()))\n",
    "    \n",
    "    X_down_sampled = np.array(data_down_sampled.drop(['Revenue'], 1).astype(float))\n",
    "    y_down_sampled = np.array(data_down_sampled['Revenue']).astype(float)\n",
    "    X_train_down_sampled, X_test_down_sampled, y_train_down_sampled, y_test_down_sampled = train_test_split(X_down_sampled, y_down_sampled, random_state=11)\n",
    "    \n",
    "    return X_train_down_sampled, X_test_down_sampled, y_train_down_sampled, y_test_down_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_majority: 10422 @ data_minority: 1908\n",
      "After Down-sampling:\n",
      "0.0    1908\n",
      "1.0    1908\n",
      "Name: Revenue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train_down_sampled, X_test_down_sampled, y_train_down_sampled, y_test_down_sampled = down_sample_minority_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8574423480083857\n",
      "Precision Score: 0.8641425389755011\n",
      "Recall Score: 0.838012958963283\n",
      "F-Beta Score: 0.8587870739265161\n"
     ]
    }
   ],
   "source": [
    "clf_down_sampled = RandomForestClassifier(max_depth=20, max_features=3\n",
    "                             , min_samples_leaf=4, min_samples_split=12, n_estimators=50).fit(X_train_down_sampled, y_train_down_sampled)\n",
    "\n",
    "predictions_down_sampled = clf_down_sampled.predict(X_test_down_sampled)\n",
    "\n",
    "print(\"Accuracy Score: {0}\".format(accuracy_score(y_test_down_sampled, predictions_down_sampled)))\n",
    "print(\"Precision Score: {0}\".format(precision_score(y_test_down_sampled, predictions_down_sampled)))\n",
    "print(\"Recall Score: {0}\".format(recall_score(y_test_down_sampled, predictions_down_sampled)))\n",
    "print(\"F-Beta Score: {0}\".format(fbeta_score(y_test_down_sampled, predictions_down_sampled, beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8574423480083857\n",
      "precision: 0.8641425389755011\n",
      "recall: 0.838012958963283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall = get_performance_metrics(clf_down_sampled, X_test_down_sampled, y_test_down_sampled)\n",
    "print(\"accuracy: {0}\\nprecision: {1}\\nrecall: {2}\\n\"\n",
    "      .format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up Sampling Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sample_minority_class():\n",
    "    # Entries of the both minority and majority classes\n",
    "    data_majority = data.loc[data['Revenue'] == 0.0]\n",
    "    data_minority = data.loc[data['Revenue'] == 1.0]\n",
    "    \n",
    "    print(\"data_majority: {0} @ data_minority: {1}\".format(len(data_majority), len(data_minority)))\n",
    "    \n",
    "    #populates the minority portion of the samples up to the size of majority portion\n",
    "    data_minority_up_sampled = resample(data_minority, \n",
    "                                     replace=True,\n",
    "                                     n_samples=len(data_majority),\n",
    "                                     random_state=142)\n",
    "    \n",
    "    # Combine majority class with upsampled minority class\n",
    "    data_up_sampled = pd.concat([data_majority, data_minority_up_sampled])\n",
    "    \n",
    "    # Display new class counts\n",
    "    print(data_up_sampled.Revenue.value_counts())\n",
    "    \n",
    "    X_up_sampled = np.array(data_up_sampled.drop(['Revenue'], 1).astype(float))\n",
    "    y_up_sampled = np.array(data_up_sampled['Revenue']).astype(float)\n",
    "    X_train_up_sampled, X_test_up_sampled, y_train_up_sampled, y_test_up_sampled = train_test_split(X_up_sampled, y_up_sampled, random_state=11)\n",
    "    \n",
    "    return X_train_up_sampled, X_test_up_sampled, y_train_up_sampled, y_test_up_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_majority: 10422 @ data_minority: 1908\n",
      "1.0    10422\n",
      "0.0    10422\n",
      "Name: Revenue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train_up_sampled, X_test_up_sampled, y_train_up_sampled, y_test_up_sampled = up_sample_minority_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9261178276722318\n",
      "Precision Score: 0.9149318018664753\n",
      "Recall Score: 0.9451242120875046\n",
      "F-Beta Score: 0.9208149700166173\n"
     ]
    }
   ],
   "source": [
    "clf_up_sampled = RandomForestClassifier(max_depth=20, max_features=3\n",
    "                             , min_samples_leaf=4, min_samples_split=12, n_estimators=50).fit(X_train_up_sampled, y_train_up_sampled)\n",
    "\n",
    "predictions_up_sampled = clf_up_sampled.predict(X_test_up_sampled)\n",
    "\n",
    "print(\"Accuracy Score: {0}\".format(accuracy_score(y_test_up_sampled, predictions_up_sampled)))\n",
    "print(\"Precision Score: {0}\".format(precision_score(y_test_up_sampled, predictions_up_sampled)))\n",
    "print(\"Recall Score: {0}\".format(recall_score(y_test_up_sampled, predictions_up_sampled)))\n",
    "print(\"F-Beta Score: {0}\".format(fbeta_score(y_test_up_sampled, predictions_up_sampled, beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9261178276722318\n",
      "precision: 0.9149318018664753\n",
      "recall: 0.9451242120875046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall = get_performance_metrics(clf_up_sampled, X_test_up_sampled, y_test_up_sampled)\n",
    "print(\"accuracy: {0}\\nprecision: {1}\\nrecall: {2}\\n\"\n",
    "      .format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "------\n",
      "Step 2\n",
      "------\n",
      "Step 3\n",
      "------\n",
      "Step 4\n",
      "------\n",
      "Step 5\n",
      "------\n",
      "Step 6\n",
      "------\n",
      "Unoptimized model\n",
      "------\n",
      "Total Time Elapsed: 1690.7716391086578 seconds\n",
      "------\n",
      "Accuracy score on testing data 0.9011\n",
      "F-score on testing data: 0.6551\n",
      "\n",
      "Optimized Model\n",
      "------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3083, 954]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-60b9e42d2600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-score on testing data: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOptimized Model\\n------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final accuracy score on the testing data: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final F-score on the testing data: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\ngrid_fit.best_params_: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3083, 954]"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "print(\"Step 1\\n------\")\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "#     ...\n",
    "#     # Create the parameters list \n",
    "#     parameters =  {\n",
    "#         'max_depth': [10,20,30,40],\n",
    "#         'max_features': [2, 3],\n",
    "#         'min_samples_leaf': [3, 4, 5],\n",
    "#         'min_samples_split': [8, 10, 12],\n",
    "#         'n_estimators': [50,100,150]}\n",
    "#     ...\n",
    "\n",
    "# Create the parameters list \n",
    "parameters =  {\n",
    "    'max_depth': [5,10,20,30,40],\n",
    "    'max_features': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [3, 4, 5, 7, 9],\n",
    "    'min_samples_split': [8, 10, 12, 20, 50],\n",
    "    'n_estimators': [50,100,150]}\n",
    "\n",
    "# Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "print(\"Step 2\\n------\")\n",
    "\n",
    "# Perform grid search on the classifier \n",
    "grid_obj = GridSearchCV(estimator=clf, param_grid=parameters, scoring=scorer)\n",
    "\n",
    "\n",
    "print(\"Step 3\\n------\")\n",
    "\n",
    "# Fit the grid search object to the training data \n",
    "grid_fit = grid_obj.fit(X_train_down_sampled, y_train_down_sampled)\n",
    "\n",
    "\n",
    "print(\"Step 4\\n------\")\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Step 5\\n------\")\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train_down_sampled, y_train_down_sampled)).predict(X_test_down_sampled)\n",
    "best_predictions = best_clf.predict(X_test_down_sampled)\n",
    "\n",
    "\n",
    "print(\"Step 6\\n------\")\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Total Time Elapsed: {0} seconds\\n------\".format((end_time-start_time)))\n",
    "print(\"Accuracy score on testing data {:.4f}\".format(accuracy_score(y_test_down_sampled, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test_down_sampled, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test_down_sampled, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test_down_sampled, best_predictions, beta = 0.5)))\n",
    "print(\"\\ngrid_fit.best_params_: {0}\".format(grid_fit.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5\n",
      "------\n",
      "Step 6\n",
      "------\n",
      "Unoptimized model\n",
      "------\n",
      "Total Time Elapsed: 2332.347555398941 seconds\n",
      "------\n",
      "Accuracy score on testing data 0.8574\n",
      "F-score on testing data: 0.8619\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8512\n",
      "Final F-score on the testing data: 0.8544\n",
      "\n",
      "grid_fit.best_params_: {'max_depth': 20, 'max_features': 4, 'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Step 5\\n------\")\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train_down_sampled, y_train_down_sampled)).predict(X_test_down_sampled)\n",
    "best_predictions = best_clf.predict(X_test_down_sampled)\n",
    "\n",
    "\n",
    "print(\"Step 6\\n------\")\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Total Time Elapsed: {0} seconds\\n------\".format((end_time-start_time)))\n",
    "print(\"Accuracy score on testing data {:.4f}\".format(accuracy_score(y_test_down_sampled, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test_down_sampled, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test_down_sampled, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test_down_sampled, best_predictions, beta = 0.5)))\n",
    "print(\"\\ngrid_fit.best_params_: {0}\".format(grid_fit.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Score: 0.9568860743299431\n",
      "Test Set Score: 0.9238150067165611\n",
      "Cross Validation Score: 0.8939983779399837\n"
     ]
    }
   ],
   "source": [
    "clf_best_down_sampled = RandomForestClassifier(max_depth=20, max_features=4, min_samples_leaf=5, min_samples_split=8, n_estimators=150, random_state = 42).fit(X_train_down_sampled, y_train_down_sampled)\n",
    "\n",
    "print(\"Train Set Score: {0}\".format(clf_up_sampled.score(X_train_up_sampled, y_train_up_sampled)))\n",
    "print(\"Test Set Score: {0}\".format(clf_up_sampled.score(X_test_up_sampled, y_test_up_sampled)))\n",
    "print(\"Cross Validation Score: {0}\".format(np.mean(cross_val_score(clf_up_sampled,X,y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "------\n",
      "Step 2\n",
      "------\n",
      "Step 3\n",
      "------\n",
      "Step 4\n",
      "------\n",
      "Step 5\n",
      "------\n",
      "Step 6\n",
      "------\n",
      "Unoptimized model\n",
      "------\n",
      "Total Time Elapsed: 6548.905949831009 seconds\n",
      "------\n",
      "Accuracy score on testing data 0.9601\n",
      "F-score on testing data: 0.9399\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.9369\n",
      "Final F-score on the testing data: 0.9185\n",
      "\n",
      "grid_fit.best_params_: {'max_depth': 40, 'max_features': 5, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "print(\"Step 1\\n------\")\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "#     ...\n",
    "#     # Create the parameters list \n",
    "#     parameters =  {\n",
    "#         'max_depth': [10,20,30,40],\n",
    "#         'max_features': [2, 3],\n",
    "#         'min_samples_leaf': [3, 4, 5],\n",
    "#         'min_samples_split': [8, 10, 12],\n",
    "#         'n_estimators': [50,100,150]}\n",
    "#     ...\n",
    "\n",
    "# Create the parameters list \n",
    "parameters =  {\n",
    "    'max_depth': [5,10,20,30,40],\n",
    "    'max_features': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [3, 4, 5, 7, 9],\n",
    "    'min_samples_split': [8, 10, 12, 20, 50],\n",
    "    'n_estimators': [50,100,150]}\n",
    "\n",
    "# Make an fbeta_score scoring object using make_scorer()\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "print(\"Step 2\\n------\")\n",
    "\n",
    "# Perform grid search on the classifier \n",
    "grid_obj = GridSearchCV(estimator=clf, param_grid=parameters, scoring=scorer)\n",
    "\n",
    "\n",
    "print(\"Step 3\\n------\")\n",
    "\n",
    "# Fit the grid search object to the training data \n",
    "grid_fit = grid_obj.fit(X_train_up_sampled, y_train_up_sampled)\n",
    "\n",
    "\n",
    "print(\"Step 4\\n------\")\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Step 5\\n------\")\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train_up_sampled, y_train_up_sampled)).predict(X_test_up_sampled)\n",
    "best_predictions = best_clf.predict(X_test_up_sampled)\n",
    "\n",
    "\n",
    "print(\"Step 6\\n------\")\n",
    "\n",
    "end_time = time()\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Total Time Elapsed: {0} seconds\\n------\".format((end_time-start_time)))\n",
    "print(\"Accuracy score on testing data {:.4f}\".format(accuracy_score(y_test_up_sampled, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test_up_sampled, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test_up_sampled, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test_up_sampled, best_predictions, beta = 0.5)))\n",
    "print(\"\\ngrid_fit.best_params_: {0}\".format(grid_fit.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8522012578616353\n",
      "precision: 0.8616071428571429\n",
      "recall: 0.8301075268817204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall = get_performance_metrics(clf_down_sampled, X_test_down_sampled, y_test_down_sampled)\n",
    "print(\"accuracy: {0}\\nprecision: {1}\\nrecall: {2}\\n\"\n",
    "      .format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9238150067165611\n",
      "precision: 0.8983859134262656\n",
      "recall: 0.9532892175943947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall = get_performance_metrics(clf_up_sampled, X_test_up_sampled, y_test_up_sampled)\n",
    "print(\"accuracy: {0}\\nprecision: {1}\\nrecall: {2}\\n\"\n",
    "      .format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Random Forest Classifier performances with normal, up-sampled and down-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3hVVdaH35UESEioQkIJvUmLSQy9CAgKKCqIBUUsOFYsqDM2BtBR9BsL6IiDimLXUewKSFEEASlCAGlKk94lJCGUkP39sU8uN8lNclNu7k2y3ue5T3LO2eecderv7L3XXkuMMSiKoihKYQnytwGKoihK6UaFRFEURSkSKiSKoihKkVAhURRFUYqEComiKIpSJFRIFEVRlCKhQlIIROQpETkkIvv8bUtZRETWiUgvf9vhS0Rkvojc6vx/vYjM9rdNim8QkV4issttuszd3+VCSERku4ikiUiKiOwXkWkiElHIbTUAHgTaGGPqFK+lgYnzIBgR+Tzb/POc+fO93M7bIvJUfuWMMW2NMV5tsyxgjPnAGHORL7bt3Pt9i7C+EZFU59k5LCLzROSaAqyf5SVaiP03dmxIcX7bReSRwm4vECiL93e5EBKHQcaYCCAe6ACMKegGRCQEaAQcNsYcKOT6pZWDQFcROcdt3o3A78W1g1J+fjxSRo7pPOfZaQW8DbwiIuNK2Ibqjg1DgX+KSL8S3r+SF8aYMv8DtgN93aafA751/q8GvAnsBXYDTwHBzrKbgEXAROAI8DOQBmQAKcDbTrnLgHXAUWA+0Drbvh8G1gAngRBn3t+deanO/qOAmUAyMBeo4baNT4F9QBKwAGjrtuxtYDLwnbPuUqCZ2/K2wBzH/v3AY878IOARYAtwGPgEqJnL+esF7AKmAHc784KdeWOB+W5lz3Xb3ybgamf+bcBp4JRz7r7J5/z0ddvPY46dycCvQANAnOtywDkva4B2udh/M7DBWX8rcHu25ZcDicAxZz/9nfk1gWnAHuAv4Eu3df4GbHaO82ugntsyA9wN/AFsc+b1AzY6tr4C/ATc6naf/Zxt/Tuc9f9yrq+4nY8XgEPANmCUUz7Ew3G/h71X05xz/o/87lcP2zBA82zzhgIngHPyOr9AOFmflxSgHtARWOLsf69zPirmsv/G2Y8PWAb83W26HvAZ9mNnG3Cv27KOwArn2u4HXizAc/Uq9plMwb4H6gCTnGuyEYjL9pw/Cqx3lk8DQt2fH0/vI2A89tl71zl/64AEt7LxwCpn2afA/4Cn/P1OzXGd/G1AiRxk1gvXwLlY/3KmvwRec276SOcmzXwQbgLSgXuwL7gwDzdFS6wY9AMqAP/AvmAquu070dlvmNu8X7DiUR/7MlwJxAGVgB+AcW77uAWo4iybBCRmu+GPOA9MCPAB8LGzrAr2QX0QCHWmOznL7ndsiHa2+xrwUS7nrxdWNLoCS515A4HvgVtxhMQ5hzuxL5YQ5yE4hPOAOrY+5eHaeDo/mdfr78Ba7NewAOcB5wAXY0WlujO/NVA3F/svAZo55S4AjgPxzrKO2BdJP6y41gfOdZZ9h31wazjX9gJnfh/nuOKdc/cfYIHb/gxWTGti75la2BfZUGc7o7H3VV5C8q1zbA2xL8hMcbsD+7KKduyaSy5Ckv1cenO/eljfk5BUcOwf4MX57YXb8+LMOx/o7NwjjbEidH8u+2/sfnzOeseBwc50kHMfjAUqAk2xYnaxs3wJcIPzfwTQuQDP1SHH1lDsM7kNGIEV86eAH7Od59+w93FNrPA85ekckFNITmCfp2DgGeAXZ1lF4E/gPuecD8F+iKmQ+OUg7YVLwX4B/Yn90gjDvshP4rzAnLLDMm8Q7AO+I9u2st8U/wQ+cZsOwtZsernt+xYP9lzvNv0Z8F+36Xtw+/rNtm5158Gq5nbDT3VbPhDY6HYsq3LZzgbgQrfputgag6cvW9cxY7+SWwEfA9eTVUiuARZmW/c1HFEkdyHxdH4yH7RNwOUebOqDbVbrDAQV8H74ErjPzb6JHsrUxX5J1/Cw7E3g327TEc65a+xMG6CP2/IROC8HZ1qwwpyXkHR3m/4EeMT5/wfcalRAXwomJHnerx7WzyEkzvx97vdwHufXde/kcT3uB77IZVljx4aj2NqNAZ7nbA2tEzmf0UeBac7/C4AngFr52ODpuXoj2zO5wW26PXA023m+I9tzuMXTOSCnkMx1W9YGSHP+7+lcG3Fb/jMBKCTlqY/kCmNMdWNMI2PMXcaYNGx/RwVgr4gcFZGj2BdLpNt6O/PZbj2sOAFgjMlw1qmfzzb2u/2f5mE6AkBEgkXkWRHZIiLHsDch2K/cTNy9x45nrov9OtqSi92NgC/cjnsDcAYrrnnxHrY5pTfwhYdtdsrcprPd67FNAnmR1zn2eAzGmB+wTSKTgf0i8rqIVPW0AREZICK/iMgRx6aBnD1/uZ2jBsARY8xfHpZlv+Yp2ObB3K55PfdpY98I+d1XuV3TLNvyYjvZ8eZ+zRMRqQDUxtaE8zu/ntZvKSLfisg+556ekFd5h1rYc/AQ9sVcwZnfCKiX7Z57jLP38UhsLWyjiCwXkUsdG7x5rrx6Rt1wvxZ/Ys+1N2S/1qFO31o9YLdzv3jaR8BQnoTEEzuxNZJajshUN8ZUNca0dStjclk3kz3YmxkAERHsS2h3AbaRF9dh2/D7YvtzGmfuyot1d2KbHHJbNsDtuKsbY0KNMbtzKZ/Je8BdwAxjzHEP2/wp2zYjjDF3OstzOw95nZ9cj8EY87Ix5nxsP1BLbDNYFkSkErbG9zwQZYypDszg7PnLbfs7gZoiUt3DsuzXPBzb3JbbNd+LvScyy4v7dAHZi23WyiS/7WQ/t97cr/lxObZpa5kX59fTtf0vto+hhTGmKvbFn+/9bIw5Y4x5AdsUdJczeye2H8r9nqtijBnorPOHMWYY9uPw/4DpzvUqynOVG+7XoiH2XBeFvUB95xp52kfAUK6FxBizF5gNvCAiVUUkSESaicgFBdjMJ8AlInKh86X2IFacFheTmVWc7R0GKmO/3rzlW6COiNwvIpVEpIqIdHKWTQGeFpFGACJSW0Quz2+Dxpht2Hbwx3PZX0sRuUFEKji/DiLS2lm+H9uGXRCmAv8SkRZiiRGRc5ztdnLOeSr25XLGw/oVsW3gB4F0ERkAuLvavgnc7Fy/IBGpLyLnOvfGTOBVEanhHEtPZ50PnXVinRfpBGzf0fZcjuE7oK2IDHG+NO8l/1pabnwC3OfYWR3rqJAX2c95oe9XEakpItdja4H/Z4w5TP7ndz9wjohUc5tXBdtnlCIi5wJ3UjCeBf4hIqHYPs1jIvKwiIQ5NY12ItLBsXm4iNR2al5HnfXPULTnKjfuFpFoEamJFcf/FXF7S7C2jhKREOf57FhUI31BuRYShxHYhyHT22I6tn3cK4wxm4Dh2A7XQ8AgrKvxqWKy711sNXm3Y+MvBbAtGdupOghbff4D2yQF8BLW22i2iCQ72+3kaTsetvuzMSbH15azv4uAa7FfY/uwX4GVnCJvAm2cJogvvTyMF7Evv9nYl8+b2P6tqsAb2Gv2J/aF8HwuNt3rbOMv7Jfo127Ll2GdAyZiO91/4uwX+w3Yvo+NWIeI+5115mH7Gj7DfjU2c47ZI8aYQ8BV2BfgYaAFtjO2MLyBPRdrsN48M7C1A08iCrbzdoxzzh8q5P26WkRSsJ3ytwKjjTFjnWPL7/xuBD4Ctjo21MM2T12H9UR6g4K/cL9z9vU3Y8wZ5xhisZ3hh7AfH5nC1R9Y59j/EnCtMeYERXiu8uBD7LXZ6vzyHTOVF841GYJtnjuKvW7fYgUwoMjssFIUpRTi1ACmGGMa5VtY8Rkish3rPDHXx/tZir3e03y5n4KiNRJFKUU4zTcDnaaO+sA4cjo9KGUEEblAROo41/tGIAaY5W+7sqNCoiilC8G6s/6FbdragB1DoZRNWgGrsc2uDwJDnf67gEKbthRFUZQioTUSRVEUpUiUuoBytWrVMo0bNy7UuqmpqYSHhxevQUqR0esSeOg1CUyKcl1+/fXXQ8aY2sVsElAKhaRx48asWLGiUOvOnz+fXr16Fa9BSpHR6xJ46DUJTIpyXUTkz/xLFQ5t2lIURVGKhAqJoiiKUiRUSBRFUZQioUKiKIqiFAkVEkVRFKVIqJAoiqIoRUKFRFEURSkSpW4ciaIoxc/Jk7B9O2zZAlu3QmJiQ7Zvh+ho+6tfH6pU8beVSqCiQqIo5QBj4PDhs0KxdevZ/7dsgd27bZmzNOXNN7Nuo2rVs6LiLjDu/59zDkhRcgwqpRIVEkUpI5w+DX/+6Vkotm6F5OSs5evWhaZNoXdvaNbM/p/5NzFxAS1a9GTXLti1ywqN+//r1sHevdnFBypVyikw2aejoiA4uOTOi+J7VEgUpRTx1185hSLz/x07ICPjbNlKlaBJEysMPXtmFYomTaBy5dz3ExqaQbNmtnxunD4N+/blFJnM/5cssdOnsuVeDA62IpZX7aZePWu/UjpQIVGUAOLMGdi507NQbN1qhcSd2rWtMHTtCsOHZxWLevUgyIfuNBUqQIMG9pcbGRlw6FDuYrNuHcyaBampOdetXTv3JrTM/yMifHd8iveokChKCZOcnLtQbN8O6elny4aEQOPGVhw6dswqFE2bBn4HeFAQREbaX1yc5zLGwLFjuYvNjh2weLHt48lOZr9NXoJTs6b22/gaFRJFKWYyMmDPHs/9FFu3wsGDWcvXqGHFIT4ehg7NKhQNGpT9/gQRqFbN/tq0yb1cWpo9r57EZtcu+O03z/02oaF5Owhov03RUSFRlEJw/Dhs2+ZZKLZts+60mQQFQcOGViCuuCKrUDRtaoVEyZ+wMIrcb7N4ce79NvXq5S042m+TOyokiuIBY2D//tzdZffty1q+ShX7gmvTBgYNOisSzZpZEalQwT/HUd4ojn6b336DmTM999tERubtkVa/fvnstyk3QvKf/8CYMd2oWdNe6CpVzv7cp/Na5j6tXyaln5Mnbe0hN3fZtLSzZUXsi6JpUxg4MKtQNG2q4ydKE77ut6lWLf/xNmWt36bcCEmbNtC79wGqVatPcrLt8My8UTKnk5OzdnTmRYUKBROe/JZVqlS2bqxAwBj75Zmbu2z2QXiVK1tRaN4cLrooq1A0amTb2pXyQUn02+TnkRYZWXr6bcqNkFx4IQQH/0GvXvXzLHfy5FlRSUnJKjLeTO/dm3U6e1tsboSEFEyU8hOp0NDyIUzug/A8NUPlNgivT5+cHlBRUeXjnCnFR0n027gLTPPmVQnEDMjlRki8pVIl+6tVq3i2d+pU4UUpORkOHMg67d6JmxfBwYVrssttWeXK/nvJZg7C8yQUuQ3Ca9bMDsJzF4r8BuEpii8ozn6bu+8OzBtYhcTHVKxo28/POad4tnf6dOFFKTnZ3qzu0ydOeLffoKCzAlMczXnh4WeF6cwZyRIwMLtoeBqE16zZ2UF47uE96tb17SA8RfEF3vbb/PjjPuDcErXNG1RIShkVKlh30eJyGU1Pz1t48hOpHTuyTrt3UOeFiBWV8HA4eLAHZ85kPcbGja04dOyYVSiaNAn8QXiK4gtEAvcjSYWknBMSAtWr219xcOaM90KUkmJ/qak76d27kUswoqNLTyejoigqJEoxExx81tvFW+bP30avXo18Z5SiKD4lQCtKiqIoSmnBp0IiIv1FZJOIbBaRRzwsbyQi80RkjYjMF5FoX9qjKIqiFD8+ExIRCQYmAwOANsAwEck+tOd54F1jTAzwJPCMr+xRFEVRfIMvayQdgc3GmK3GmFPAx8Dl2cq0AeY5///oYbmiKIoS4PhSSOoDO92mdznz3FkNXOn8PxioIiLFNOJCURRFKQl86bXlaRx0togzPAS8IiI3AQuA3UCOaFcichtwG0BUVBTz588vuDFnznBy//5Crav4lpSUFL0uAYZek8AkUK+LL4VkF+AeFCAa2ONewBizBxgCICIRwJXGmKTsGzLGvA68DpCQkGB6FSbYzMsvc/qf/6TCiy/CzTcH7siecsj8+fMp1DVVfIZek8AkUK+LL9+my4EWItJERCoC1wJfuxcQkVoikmnDo8BbPrOmTx9SGzWCW2+FHj1gzRqf7UpRFKU84TMhMcakA6OA74ENwCfGmHUi8qSIXOYU6wVsEpHfgSjgaV/ZQ7t2JE6aBG+9BZs22bymDz6YMzysoiiKUiB82r5jjJlhjGlpjGlmjHnamTfWGPO18/90Y0wLp8ytxhgvY9sWkqAg26y1aZP9++KL0Lo1fPZZzoQBiqIoileUz46Cc86BN96wiQBq1YKhQ+GSS2yoWUVRFKVAlE8hyaRLF1ixwtZMFi6Etm3hX//yPumHoiiKUs6FBGz429GjYeNGGDQIxo6FmBiYNy//dRVFURQVEhf168Mnn9g0ZGfOQN++cN11NneuoiiKkisqJNnp3x/WrrU1k88+g3PPhf/8hyyZlxRFURQXKiSeCAuDJ56wiZI7dYJ777Wp+pYt87dliqIoAYcKSV60aAHffw8ff2ybuDp3hjvvzJlEXFEUpRyjQpIfInDNNbYz/t574fXXbXPXe+/p2BNFURRUSLynalWYNMm6CzdpAiNGQO/esH69vy1TFEXxKyokBSUuzg5knDIFVq+G886DRx+F48f9bZmiKIpf8GX037JLUBDcfjsMHgz/+Ac8+yx89JH17ho0yN/WFQiTYThz6gzpJ9Lt72S66/8zJ8/kPs9tfvZ5Z07ksV72eSfTCQoPYmuLrVRrWI2qDapSrWG1LL/Q6qGIeMpKoChKIKBCUhQiI+Htt+GWW2wn/GWX2d/LL0OjRnmuaowhIz2jQC9sb8oWdFtnThWDW7NASGgIIZVC7N/QEIIrBbv+D6kUQqWqlQiPDHfNd/2tGMy237YRfCqY3Ut3s+GzDTlsqhBeIYuwZBebqtFVCamkt7Ki+Ity+fSZDJPr13Shv8bjnuRMyAbSv9tI+rfjSG/UlPTadTlzKiPX7ZuMonfWB1UIyvclHlotNOvLO9vy3NbztmxQSFCRagzuORZMhiH1QCpJO5Lsb6f9e2zHMZJ2JLEvcR+p+1NzbCM8KjxXoanWoBrhkeFIkNZqlMDHGEPakTRS96eSsi/F/vbbv2mN0mzM9ACj3AjJLy/9ws+P/czC0wvJOJ1R9A1mfoVnecHWILhlR0L27SJk2zZCD+wlJLYtIS3r+OYlXimkzL0cJUiIqBNBRJ0I6nfMnpnZkn4inWO7jmURmkyxObj+IJtnbub08dNZ1gmuGJxFYDyJTcWIiiVxiEo5xBjDqeRTOYQhZV9KFsFI3Z9Kyv4Uj++o4IrBNLunmR+sz59yIyRR7aOoM7AOjZs3LpaXeL5f4d98A/fcA4umWA+v556zTWFKkQkJDaFm85rUbF7T43JjDCf+OuFRaJJ2JrHth20k707OUSMMrRGap9BUqVeFoBD1T1HOcvr46RzikEMYnP/TT+TIIo4ECxFREYRHhRNRJ4KomCjX/xF1IoiIinD9X6laJX766Sc/HGX+lBshadKnCc2DmpdcmspBg+DCC+Gpp+D5562wPPMM/O1vmubXx4gIYTXDCKsZRp3YOh7LZKRnkLwnOYvQJO1I4thOW9PZ8fMOTvx1Iut2g4Qq9au4hKVqw5xiE1pDHQNKO+kn0101g1xrDc7/p1JO5dyAQHjtcJcgNGzekPA64TmEITwqnMrnVC4TrQrlRkj8QuXKMGEC3HAD3HUX3HGHzdA4ZYp1I1b8RlBIkEsA6Oa5zKmUU7kKze7lu9nwed6OAZ5qNVWjqxISqo9dSZORnkHqQc9ikL0vIvsHRCahNUJdIlAvoV6u4hBeO7zc1Vz1ji4JWreGH36ADz6w6X0TEmDUKJv7pGpVf1un5ELFiIrUbl2b2q1re1xuMgypB1M9Co1XjgHZazUN7F91DPAOk2E4fvh4TkHYn0LqvtQszU3HDx0HD74tFatUdIlBZLtImvRtkkMYIupEEB4Zrp6BeaBnpqQQgeHDbSbGxx+3Y04+/RQmToSrr7bLlVKFBNn27YioCOp3yMUx4KSbY0A2oTm44SCbv9/M6dRcHAMcYXGJTYOztZuy6hhgjOHE0RMeawrZxSH1QCrmTE51CAkNcQlBzWY1adC1QQ5hyBSPCpUr+OEoyx4qJCVNjRrw6qtw00127Mm118Kbb8Irr0DLlv62TilmQiqFULNZTWo2y8Mx4OgJj0KTtCOJbT9uI3lPco4XpssxIJdaTSA5BhhjOJVyyqM7q6dmJk9jm4IqBLlqClXqVaFufF2PwhBRJ4KKVSpqP1UJo0LiLzLD0v/3v7aG0r49PPywDbcSFuZv65QSQkQIqxFGWI0w6pyXh2PA3uRcxWbn4p2kHUnLut1Mx4A8ajVFdQw4nXY6S3NSXv0P2d2xM20Mjwx3CULtNrVzFQd1YghsVEj8SXCw7Su58krbd/Kvf8GHH9raSf/+/rZOCRCCQoKsADTwzjEgu9DsWbEnd8eAXITm2O/H+D319zw7pk8eO+nRlsq1KrvEILpLdK7urGHnhBEUHBi1JqVoqJAEAnXrWgG55Ra4+24YMACGDrXRhut7bntXFHcK4hiQXWiO7TzG/jX7SdmXkmWdVaxy/R9aPdQlCHVi6+TusRQZTnCFYJ8eqxJ4qJAEEn37wpo1dvDi00/DrFk2U+O990KIXiql8BTEMeDYzmOsWLyCzhd2domFuiwreaH1ykCjUiUYMwbWrYMePWyT1/nn29D1iuJDMh0DGvdqTK2utYjuFE31RtVVRJR8USEJVJo2he++g88+gyNHoFs3Oyr+8GF/W6YoipIFFZJARgSGDIENG2zNZNo0aNXKjo7PKIbAk4qiKMWACklpICLCxutatcrmix85Enr2hLVr/W2ZoihK/kIiIpVF5J8i8oYz3UJELvW9aUoO2reHBQvsAMaNG228rr//HVJS8l9XURTFR3hTI5kGnAS6ONO7gKd8ZpGSN0FB1k140ya4+WZbU2ndGj7/HEzRE2UpiqIUFG+EpJkx5t/AaQBjTBqgQ0z9zTnnwBtvwKJFULOmHdR46aWwdau/LVMUpZzhjZCcEpEwnNiZItIMW0NRAoGuXeHXX+GFF2yzV9u2dgzKSb1EiqKUDN4IyThgFtBARD4A5gH/8KlVSsEICYEHHrDeXZdeasehnHeeDV2vKIriY/IVEmPMHGAIcBPwEZBgjJnvW7OUQhEdbUPTz5gBp0/bDI3XXw/79vnbMkVRyjDeeG31BNoCycAxoI0zTwlUBgyA336Df/4Tpk+3Y09eeQXO5AzPrSiKUlS8adr6u9vvn8A3wHgf2qQUB2Fh8OSTdqxJhw5wzz3QqRMsX+5vyxRFKWN407Q1yO3XD2gH7Pe9aUqx0LIlzJkDH30Eu3dbMbnrLjh61N+WKYpSRijMyPZdWDHJFxHpLyKbRGSziDziYXlDEflRRFaJyBoRGVgIe5T8ELGZGDdutPlPXnvNNne9/76OPVEUpch400fyHxF52fm9AiwEVnuxXjAwGRgAtAGGiUibbMXGAJ8YY+KAa4FXC3oASgGoVg1eftk2bzVuDDfcAH36WG8vRVGUQuJNjWQF8KvzWwI8bIwZ7sV6HYHNxpitxphTwMfA5dnKGKCq8381YI9XVitFIz7ehqWfMgUSE62r8GOPwfHj/rZMUZRSiBgfNW2IyFCgvzHmVmf6BqCTMWaUW5m6wGygBhAO9DXG/OphW7cBtwFERUWd//HHHxfKppSUFCIiIgq1blmlwl9/0WzKFOrMnk1anTpsvvdeDnfpkv+KxYhel8BDr0lgUpTr0rt371+NMQnFbBKQh5CIyFqc0ezZFwHGGBOT54ZFrgIuziYkHY0x97iVecCx4QUR6QK8CbQzxuQaIz0hIcGsWLEin8PyzPz58+nVq1eh1i3z/PQT3Hmnbea64gp46SVo2LBEdq3XJfDQaxKYFOW6iIjPhCSv1GdFjfC7C2jgNh1NzqarkUB/AGPMEhEJBWoBB4q4b6WgXHCBbeaaONGm923dGsaNg9GjoUIFf1unKEoAk2sfiTHmz7x+Xmx7OdBCRJqISEVsZ/rX2crsAC4EEJHWQChwsHCHohSZihXh4YdtraRvX/t/XBwsXOhvyxRFCWC88drqLCLLRSRFRE6JyBkROZbfesaYdGAU8D2wAeudtU5EnhSRy5xiDwJ/E5HV2PArNxlfddoo3tOoEXz1lf0lJ9skWjfdBAdV4xVFyYk3XluvAMOAP4Aw4FbgP95s3BgzwxjT0hjTzBjztDNvrDHma+f/9caYbsaY84wxscaY2YU7DMUnXHYZrF8PjzwCH3xgx568/rqm+VUUJQteDUg0xmwGgo0xZ4wx04DevjVLCRjCw+GZZ2D1aoiJgdtvh27dbH+KoigK3gnJcaePI1FE/i0io7Guukp5ok0b+PFHeOcd2LIFzj8f7r8fjuXbyqkoShnHGyG5wSk3CkjFemJd6UujlABFBEaMsGl+b7vNjpI/91z43/801IqilGNyFRIReUhEGjheWieMMceMMU8YYx5wmrqU8kqNGvDf/8KSJVCnjo3j1b8//PGHvy1TFMUP5FUjqQ8sFpEFInKniNQqKaOUUkKnTrBsma2Z/PILtG8P48fDiRP+tkxRlBIkr3Eko4GG2BwkMcAaEZkpIiNEpEpJGagEOCEhNtfJxo0wZIgdzNiuHXz/vb8tUxSlhMizj8RYfjLG3IntG5kEjEbzkSjZqVsXPvzQ5j4JDrZNXVdfbXOgKIpSpvHK/VdE2gNPYsPCnwIe86VRSimmb19Ys8ZmZ/z6a9sZP2kSpKf72zJFUXxEXp3tLUTknyKyHvgQOA5cZIzpZIyZVGIWKqWPSpVsvvh166B7dxuvKyHBds4rilLmyKtG8j029tU1xpj2xpinjTFbS8gupSzQrBnMmAHTp8OhQ9C1q3UbPnLE35YpilKM5NXZ3tQY87gxZm1JGqSUMUTgyittIMgHHoC33rKhVt5+W8eeKEoZoTA52xWl4FSpAi+8ACtXQosWcPPNNhjkb7/52zJFUYqIColSssTEwM8/w9SpNiBkXBx1v/nG31YpilIEvPXaChORVvN8a2wAACAASURBVL42RiknBAXByJE21ErfvrScOBE+/9zfVimKUki8yUcyCEgEZjnTsSKSPUGVohScWrXgs8841ro1XHcdLFjgb4sURSkE3tRIxgMdgaMAxphEoLHvTFLKFZUrs3bCBGjc2OY/Wau+HYpS2vBGSNKNMUk+t0Qpt6RXq2ZDqlSuDAMGwM6d/jZJUZQC4I2Q/CYi1wHBziDF/wCLfWyXUt5o1AhmzbKpfS++WMeaKEopwhshuQdoC5zEjnBPAu73pVFKOSUmxuaJ37LFNnOlpfnbIkVRvCBfITHGHHcGJnZwfmOMMRonXPENvXrBe+/B4sUwbJjG6FKUUoA3XltzRKS623QNEdEY4YrvuPpqeOklWzsZNUpHwCtKgBPiRZlaxpijmRPGmL9EJNKHNimKzXGyZw88+yzUr2+DQCqKEpB4IyQZItLQGLMDQEQaAfqJqPieCROsmIwda/Od3Hqrvy1SFMUD3gjJ48DPIvKTM90TuM13JimKg4gNpbJ/P9x+O0RG2k54RVECCm8622cB8cD/gE+A840x2keilAwVKtgw9PHxcM01thNeUZSAwtugjZWAI1jX3zYi0tN3JilKNiIi4LvvIDoaBg2y+eEVRQkY8m3aEpH/A64B1gEZzmwDaGAkpeSIjLSj37t0sQMWlyyBevX8bZWiKHjXR3IF0MoYc9LXxihKnjRtCjNnwgUXQP/+Nshj9er5r6coik/xpmlrK1DB14YoilfEx9uQ8xs2wBVXwAkdG6so/sabGslxIFFE5mHDpABgjLnXZ1YpSl7062dT9Q4fDiNGwMcf2xwniqL4BW+E5GvnpyiBw/XXw7598NBDUKeOHQkv4m+rFKVckq+QGGPeKQlDFKXAPPgg7N4NEyfa0e8PP+xvixSlXOKN11YL4BmgDRCaOd8Y09SHdimKdzz/POzdC488YmsmN97ob4sUpdzhTdPWNGAcMBHoDdwMaBuCEhgEBdn+koMHbR74yEibHEtRlBLDmx7KMGPMPECMMX8aY8YDfXxrlqIUgEqVrCdX+/YwdCgsX+5vixSlXOGNkJwQkSDgDxEZJSKDAY3+qwQWVavaMSZRUXDJJfDHH/62SFHKDd4Iyf1AZeBe4HzgBsCrhmgR6S8im0Rks4g84mH5RBFJdH6/i8hRT9tRFK+oU8em6zXGjn7ft8/fFilKucAbr63MdoIUbP+IV4hIMDAZ6AfsApaLyNfGmPVu2x7tVv4eIM7b7SuKR1q2hG+/hT59YOBA+OknqFLF31YpSpnGmwyJCSLyhYisFJE1mT8vtt0R2GyM2WqMOQV8DFyeR/lhwEfema0oedCpE3z6KaxZA0OGwKlT/rZIUco03nhtfQD8HVjL2aCN3lAf2Ok2vQvo5KmgkyyrCfBDLstvw8mBEhUVxfz58wtgxllSUlIKva7iO3xyXSpXps5DD3Hu//0f+y+5hA2PPqqj3wuAPiuBSaBeF2+E5KAxpjAj2z25COeWWfFaYLox5oynhcaY14HXARISEkyvXr0KYQ7Mnz+fwq6r+A6fXZdevaBqVaIef5yo2Fh47rni30cZRZ+VwCRQr4s3QjJORKYC2WNtfZ7PeruABm7T0cCeXMpeC9zthS2KUjAefdSm633+eZuu94EH/G2RopQ5vBGSm4FzsRGA3fOR5Ccky4EWItIE2I0Vi+uyFxKRVkANYImXNiuK94jYOFz79tmQKnXrwrBh/rZKUQpOYiKc8dho43e8EZLzjDHtC7phY0y6iIwCvgeCgbeMMetE5ElghVtz2TDgY2NMbs1eilI0goPh/fft6Pcbb7Sj3y+80N9WKYp3GAP//S/cdx/Rf/tbQN673gjJLyLSxt1t11uMMTOAGdnmjc02Pb6g21WUAhMaCl99BT16wODB1i04Tr3NlQDn5EkYNQqmToVLLmHvwIE097dNHvDGjaU7Nh/JJsf1d62X7r+KElhUr24HLFavbuNxbdvmb4sUJXf27bPjoaZOhcceg6++4kxEhL+t8og3NZL+PrdCUUqK+vWtmHTvbke/L1oEtWv72ypFycqKFTYD6F9/wSefwFVX+duiPMmzRuLE2PrOCdaY5VdC9ilK8dOmDXzzDezcaeNypab62yJFOcv779sPnZAQWLw44EUE8hESY0wGsFpEGpaQPYpSMnTrZlP0/vorXH01nD7tb4uU8k56us34ecMN0KWLjWJ93nn+tsorvOkjqQusE5F5IvJ15s/XhimKz7n8cusNM2MG3Hab9Y5RFH9w5IiNDffCC7ZzffbsUtXk6k0fyRM+t0JR/MVtt9kBi088AfXqwdNP+9sipbyxbp39qNmxw3asjxzpb4sKjDfRf38SkSiggzNrmTHmgG/NUpQSZNw4KyYTJtgBi6NG+dsipbzw1VcwfDiEh8P8+dC1q78tKhTeRP+9GlgGXAVcDSwVkaG+NkxRSgwRePVVuOwyuPdemD7d3xYpZZ2MDHjySeuZ1bq19dIqpSIC3jVtPQ50yKyFiEhtYC6gT5tSdggJgY8+gn794Prrbfv0BRf42yqlLJKSYiMsfP45jBgBr71mB8yWYrzpbA/K1pR12Mv1FKV0UbmydQtu2tS2Wa9d62+LlLLG1q3WI+vLL2HiRHj77VIvIuCdIMwSke9F5CYRuQn4jmxhTxSlzFCzph2wGB4O/fvbDlBFKQ7mzYMOHWD3bnuP3X+/bVYtA+QqJCJSCcAY83fgNSAGOA943RjzcMmYpyh+oFEj+6CnploxOXLE3xYppRljYNIkG0mhbl07PqRfP39bVazkVSNZAiAi7xljPjfGPGCMGW2M+aKEbFMU/9G+vfWo2bIFBg2CtDR/W6SURk6cgJtvhtGj7X20ZAk0a+Zvq4qdvDrbK4rIjUBXERmSfaEXia0UpXRzwQXwwQd25Pu118Jnn9lOeUXxhj17bKTpZctg/Hj45z/LbLrnvJ6KO4DrgerAoGzLvElspSiln6FDbWKse++Fu++GKVPKTLu24kOWLIEhQyA52XpnDR7sb4t8Sq5CYoz5WUQWA7uMMTrcVym/3HMP7N0LzzxjR7+PG+dvi5RAZto0uOMOiI6GOXOgXTt/W+RzvAnaeGkJ2aIogcvTT1vf//Hj4fXX/W2NEoicPm1rrrfcAj172k71ciAi4J3772wRuVJE6/NKOUYE3njDJsS68074WuOWKm4cOmS9sv7zH9uxPnOmdSUvJ3gjJA8AnwKnROSYiCSLyDEf26UogUeFCvDpp3D++XDNNTZXhKKsWWPHhyxeDO+8Ay++WO6cMvIVEmNMFWNMkDGmgjGmqjNdtSSMU5SAIzwcvvvOtn9feils2OBvixR/Mn26Hal+6hQsWGBDnpRDvAnaKCIyXET+6Uw3EJGOvjdNUQKU2rXh+++hYkXbnLF7t78tUkqajAzrznvVVTb51IoV0LH8vha9adp6FegCXOdMpwCTfWaRopQGmja17eBHj9p+k6NH/W2RUlIcO2aj9j71lM0d8uOPdsR6OcYbIelkjLkbOAFgjPkLqOhTqxSlNBAXZ8cIbNxoXywnTvjbIsXX/PEHdO5ss2r+5z/WAaNSJX9b5Xe8EZLTIhKMHYSYGUY+w6dWKUppoW9fG8H1p59sru0zZ/xtkeIrZs2yzVcHDsDcuTYBmjqzAt4JycvAF0CkiDwN/AxM8KlVilKauO46m2t7+nS47z7N/V7WMAaeew4uuQQaNrT9Ib16+duqgMKbVLsfiMivwIWAAFcYY9RVRVHceeABG1vphRegfn149FF/W6QUB2lpcOut8OGHtmN92jTruadkIVchEZFQbLyt5sBa4DVjTHpJGaYopY5//9uGUnnsMdv5etNN/rZIKQo7dtgYWatW2cgGjz6qTVm5kFeN5B3gNLAQGAC0Bu4vCaMUpVQSFGS/WA8csF+xUVHWo0spffz8M1x5pa2RfP21HTOk5EpefSRtjDHDjTGvAUOBniVkk6KUXipWtOHmY2Js5OBly/xtkVJQXnsN+vSBatVg6VIVES/IS0hOZ/6jTVqKUgCqVrXuoVFRtoP299/9bZHiDadO2Thqd9wBF15oPwJat/a3VaWCvITkPCe21jERSQZiNNaWonhJnTp29DvYdL379vnXHiVvDhywrtxTpsDDD8O330L16v62qtSQq5AYY4Kd2FqZ8bVCNNaWohSAFi1sXK79+2HgQDsiWgk8Vq6EhAQb9v3DD+HZZyE42N9WlSrKZt5HRQkUOna040vWrLEZ806d8rdFijsffQTdu9v/Fy2CYcP8a08pRYVEUXzNgAHw5pswb551Cc7QwBB+58wZ24R13XW2NrJiBcTH+9uqUkv5CpqvKP7ixhvtGJNHH7VjTF54wd8WlV+OHrU1j1mzbMf6Sy9Zbzul0KiQKEpJ8fDDdvT7iy/a3O8PPuhvi8ofGzbA5ZfDtm22Y/322/1tUZnAp01bItJfRDaJyGYReSSXMleLyHoRWSciH/rSHkXxKyIwcaIdX/LQQ7ZjVyk5vv0WOnWCpCQb+l1FpNjwWY3EiRg8GegH7AKWi8jXxpj1bmVaAI8C3Ywxf4lIpK/sUZSAIDgY3nsPDh60/SW1a0O/fv62qmxjDDzzDIwZY0P/f/klNGjgb6vKFL5s2uoIbDbGbAUQkY+By4H1bmX+Bkx2cpxgjDlQmB2dPn2aXbt2cSKffBDVqlVjg6ZGDTjK5XWZPNmOLUlPh9WrfdpGHxoaSnR0NBUqVPDZPgKW1FS4+Wb49FPbsf7GG1C5sr+tKnP4UkjqAzvdpncBnbKVaQkgIouAYGC8MWZW9g2JyG3AbQBRUVHMnz8/y/KIiAiioqKoX78+kkdQtTNnzhCs/uEBR3m9LlK3LpV37oSMDI5HRmJ8ICbGGJKSkli9ejUpKSler5eSkpLjOStthO7bR7vHHyd82za23n47O6+5ptSHrAnU6+JLIfH0Rs+eqCEEaAH0AqKBhSLSzhiTJW+pMeZ14HWAhIQE0ytbLoANGzYQHR2dp4gAJCcnU6VKlQIcglISlOvrEhYGGzcSsWcPnHsu+KDWUKVKFVJSUkhISPB6nfnz55P9OStVzJ9vE0+lp8OMGTTr359m/rapGAjU6+LLzvZdgHtDZDSwx0OZr4wxp40x24BNWGEpMPmJiKIEJGFhdgT8qVOwebNPMiyWq2fDGHjlFRvupHZtWwPp39/fVpV5fCkky4EWItJERCoC1wJfZyvzJdAbQERqYZu6tvrQJkUJPCIioFkz256/ZYsOWCwsJ0/C3/4G99xjQ9IsXQotW/rbqnKBz4TEiRg8Cvge2AB8YoxZJyJPishlTrHvgcMish74Efi7MeZwkXdep451tcz2q1K1qsf5+f7q1Ml3lyLCDTfc4JpOT0+ndu3aXFrAENSNGzfm0KFDBS7TqVMnYmNjadiwIbVr1yY2NpbY2Fi2b9/u9b4ff/xxfvzxxwLZmxvdu3cnMTExy7zPPvuMoUOHuqb/9a9/ce6557qmv/jiC4YMGQLAxRdfTHJyMkeOHGHKlCmuMnPnzuWKK67Id//Dhw+nSZMmxMbGct555xXbcWUydepUateuTVxcHC1atKB///788ssv+a73+eefs3HjxpwLqleHRo1sPK4//9R0vQVl717o3dtGEBgzxnpmVdWQgCWFTwckGmNmADOyzRvr9r8BHnB+xcf+/cW6OW+2Fx4ezm+//UZaWhphYWHMmTOH+vXrF68debB06VIA3n77bVasWMErr7zisVxeHdtPP/20z+wD6NatG/fcc49resmSJYSHh3P48GGqVKnC4sWL6datGwDfO5FzN2/ezJQpU7jjjjsKvL+JEydyxRVXMGfOHO66665i9wy7/vrrmTRpEmAF7vLLL2fhwoW0zOMr+PPPPycoKCiLgLqoXRtOn7aDFitUgOjoYrW3zLJsmc1kePSo9c5y+1hRSgaNtVWMDBgwgO+++w6Ajz76iGFuAeCOHDnCFVdcQUxMDJ07d2bNmjUAHD58mIsuuoi4uDhuv/12jNuX6Pvvv0/Hjh2JjY3l9ttv50wh2s/T09OpXr06Y8aMoWPHjixbtoxx48bRoUMH2rVrxx133OHa5/Dhw/nyyy8BiI6OZvz48cTFxRETE8PvTk6NlJQUbrrpJjp27EhcXBzffPMNAMePH+eqq64iJiaGa6+91qMrdp06dQgNDWX79u0YYzhw4ACXXXYZyxxPmsWLF9O1a1fX/o8ePcojjzzCpk2biI2N5ZFH7JjW5ORkhgwZQqtWrRgxYkS+56BLly7s3r3bNe3p+Pfs2UOnTtap8Ndff0VE2LPHduk1adIkX9fyvn37MnLkSN544w0ApkyZQocOHTjvvPO46qqrSEtLY+HChcyYMYPRo0e7aos5ylWvbgVl377i/yAqi7z7LvTsad2nFy9WEfETKiTFyLXXXsvHH3/MiRMnWLNmjevFBPblFRcXx5o1a5gwYYLrBfjEE0/QvXt3Vq1axWWXXcaOHTsA64n2v//9j0WLFpGYmEhwcDAffPBBoexKSkoiPj6eZcuW0aVLF+677z6WL1/O2rVrSUpKYtasHB7XgHW1XrVqFbfeeisvvvgiAE8++ST9+/dn2bJl/PDDDzz44IOcOHGCV155hRo1arBmzRoefvhhVq1a5XGbXbt2ZfHixaxfv55zzz2Xzp07s2zZMk6dOsW6des4//zzs5R/9tlnadWqFYmJiTz77LMArFy5ksmTJ7N+/Xo2bNiQb5PSrFmzsjSHeTr+evXqkZSURGpqKgsXLiQhIYGFCxeyZcsWoqOjCQ0Nzfc8x8fHu5qtrrrqKpYvX87q1atp1qwZb7/9Nj169GDgwIFMnDiRxMREGjdunLPcO+9Aw4a2qWvnTjhyJN/9lkvS0+GBB2wMs65dbQj4887zt1XlFo21VYzExMSwfft2PvroIwYOHJhl2c8//8xnn30GQJ8+fTh8+DBJSUksWLCAzz//HIBLLrmEGjVqADBv3jx+/fVXOnToAEBaWhqRkYUb+F+xYkUGDx7smp43bx7PPfccJ06c4NChQ5x//vkM8JBbPLO/4vzzz2fGDNtCOXv2bGbOnOl6qZ84cYIdO3awYMEC/vGPfwAQFxdH27ZtPdrSrVs3Fi9eTGpqKl26dKFTp05MmDCBX3/9lXbt2lHRi7EUnTt3pm7dugCuL/vOnTvnKDd69GhGjx7NoUOHXLWevI6/S5cuLF68mIULF/LYY48xd+5c0tLS6NGjR742AVlqk2vWrGHs2LEcPXqU5OTkXPvKPJYTgaZNbWbFbdtsM1d5dY/2xJEjcM01MHeu7Vh/4QWfuE0r3qNCUsxcdtllPPTQQ8yfP5/Dh8/6DRgPnaeZbpme3DONMdx4440888wzRbYpLCzMtY/jx48zatQoVq5cSf369RkzZkyuzTaVKlUCIDg4mPT0dJddX375Jc2a5fTK98bNtGvXrrzxxhukpqZyzz33UL16dZKTk1mwYIGrfyQ/Mu3Kblt2Jk6cyKBBg5g4cSI33XQTS5cuzfP4e/TowYIFC9i9ezeDBg3iueee4+TJk1kcBPJi1apVtHZSs44YMYKZM2fSrl07pk6dmmutKddyQUHQvDls3Gjdglu10hHZAL/9ZoMu7tplO9ZvucXfFilo01axc8sttzB27Fjat2+fZX7Pnj1dTVPz58+nVq1aVK1aNcv8mTNn8tdffwFw4YUXMn36dA4csFFjjhw5wp9//llk+9LS0ggKCqJWrVokJye7aknecvHFF/Pyyy+7pjObsNyPY/Xq1axbt87j+u3bt+fPP//kl19+ISYmBoB27drx+uuvu/pH3KlSpQrJyckFstGd4OBgHnzwQY4fP868efPyPP6ePXvyzjvvcO655xISEkKVKlWYPXu2R7uy8+OPP/LWW28xcuRIAFJTU6lTpw6nT5/mQ7fgjNmPJ7dyAISE2DEmQUHwxx/WvbU888UX0LkzHD9uBxyqiAQMZVNIoqL8tr3o6Gjuu+++HPPHjx/PihUriImJ4ZFHHuGdd94BbN/JggULiI+PZ/bs2TRs2BCANm3a8NRTT3HRRRcRExNDv3792Lt3b5EP5ZxzzuHGG2+kXbt2DB48OEs/jjeMGzeO48eP0759e9q2bcv48eMBGDVqFIcPHyYmJoaJEyfmOoo6KCiIhIQEoqKiCAmxFeKOHTuydetWjy/sqKgoEhISaN++vauzvaCICGPGjOHf//53nsffvHlz0tPT6dmzJ2Cb4TIF3xMffPABsbGxtGzZkv/7v//jyy+/pFWrVoDtS+rYsSP9+vWjTZs2rnWGDRvGhAkTXE1yuZVzUamSFZOMDCsmudS+yjQZGTB+vM0w2batTULVpYu/rVLcEE9NLoFMQkKCWbFiRZZ5GzZscDUp5EW5DsURwOh18YLkZNtnUrmyHWRXwNhk3j4jmQRMKI7kZBgxwo4LufFGm0PEC8eHskpRrouI/GqM8T5OTgEomzUSRSlrVKliO+BTU2Hr1vIxYHHLFlvz+OYbm8dl2rRyLSKBjAqJopQWatSwrsFJSWV/9PucOdChgx2cOWsW3H+/9WZTAhIVEkUpTURG2pzvhw7ZsCBlDWNs7aN/f6hf344P6dvX31Yp+aDuv4pS2qhXz0YLzgylUru2vy0qHk6csOlv333Xhjx5910b0FIJeLRGoiilDREb4LFaNdvE5biMl2p277ahTt59F554AqZPVxEpRaiQKEppJCjIdr6Hh9vO9wJkPww4Fi+GhATYsMGOFRk71h6fUmook01bz9d5ntT9qcW2vfCocB7a91CeZUSE4cOH89577wE2WGLdunXp1KkT3377bY7yjRs3ZsWKFdSqVYuIiIg806AOHjyYbdu2kZKSwsGDB2nSpAkAr776qsexFxkZGdSqVYvt27dTtWpVdu3aRYMGDViyZAmdO3fGGEOtWrXYsmULH3zwAdWrV+f666/nrbfeYuDAgdRxwuZHR0fz22+/Ub169Vxtmzt3LldeeSVNmzYlNTWVunXr8vDDD+cIEeMr9u7dy8iRI9m9ezenT5+mefPmfP119rQ3xcfmzZsZOnRojhD5eTF8+HCGDh2aI/z98OHDWbRoEVWrViUtLY0uXbrwzDPPUK9evTy39+KLL3LXXXfZ+F+Zo9//+MNmWAwLK9Rx+Y0334Q777ROBHPn2nEiSqmjTMp+cYqIt9tzDyMPFGsY+S+++ILExESmTp1Kjx49SExMJDExMdcR10FBQXTo0MEVbmPRokXExcWxePFiANavX0+9evWoXr06d999N9dffz0Ab731Fvv27Suwfb1792bVqlX8/vvvTJw4kTvvvJOffvqpkEdbMMaMGcMll1zC6tWrWb9+PU899VSJ7Le4mDhxIqtXr2bjxo20b9+ePn36cPr06TzXefHFF8+GtalQwY4ryRz9fupUCVhdDJw+beNk3Xor9OplQ8GriJRayqSQ+Iu8wsjnFS7eF2QGRwQbnn306NFZpjNFaMyYMUyaNIn//e9/JCYmcs011xAbG8sp54U0adKkHKHk8yI+Pp7HH3/clQ9l27Zt9O7d2zU6f9euXaSnp9O0aVMADh06RLVq1Vy2denShe3btzNmzBhGjhzJBRdcQNOmTZk8ebLH/e3du5dot7wdmWFXjh07Rp8+fYiPjycmJsZVK9y8eTPt2rXjlltuoW3btowYMYLvv/+erl270rJlSzIHu44ZM4Ybb7yR3r1706JFC956660c+05PT+eBBx6gY8eOxMTEMHXqVMDWCO+66y7atGnDoEGD8k1UBlb8H3roIWrWrMns2bMBuO2220hISKBt27Y8+eSTgBWeAwcO0KNHD/o63ky33XMPCTffTNvBg3nygQcCf/T7wYNw0UU2Je6DD8KMGVCzpr+tUoqACkkxklcY+dzCxfuKzHDtAMuXL2fo0KGubInuCaQyyRSQTEHJjMLrKZR8friHU7/rrru49dZbWbNmDVdddRX3338/ISEhNG3alE2bNvHzzz8TGxvLwoULSUtL48CBAzRu3BiA33//nTlz5vDLL78wduxYj/lYRo0axY033kifPn2YMGGCK4xMWFgYX331FStXrmTu3LmMHj3atc6mTZt46KGHWLt2LWvWrGH69OksXryYZ555xhXVGGDt2rXMnDmTRYsWMXbsWPZnyw/y+uuvExkZybJly1i+fDmTJ09mx44dTJ8+nW3btvHbb7/x3//+13UdCnrunn32WVasWMHq1auZM2cO69evZ/To0URGRrJw4ULmzp17ttzKlaxevpw5ixaxftaswE3Xm5hox4csWWI71p9/3sYUU0o1KiTFSF5h5BcsWMDw4cOBrOHifUXnzp1ZsWKFq+8lLCyMhg0bsn379iw1kvxwDyXvbdpe99rW0qVLufbaawEb6XbhwoXA2Ui7CxYs4MEHH2ThwoUsXbo0i/heeumlVKxYkcjISGrWrMnBgwdz7GvgwIFs2bKFkSNHsn79euLi4jh8+DDGGB5++GFiYmK46KKL2Llzp6tm0Lx5c9q0aUNQUBBt2rRxfdm3b98+yzFeccUVhIaGEhkZSc+ePVm+fHmWfc+ePZtp06YRGxtLp06dOHr0KH/88QcLFixg2LBhBAUFER0dXaCQFu7n7qOPPiI+Pp74+Hg2bNjA+vXrPa7jKterFxt27GD9unU2/HygDVj85BPo1s3WmBYuBLfU1ErpRoWkmMkMI+/erJWJN2HWi4uIiAgaNWrEtGnTXAEUO3fuzDfffENSUhLNmzf3ajueQsnnh3s49dzo0aMHCxcuZMWKFfTv359Dhw6xYMECV8BE93277//ll1925aPPjIx8zjnncP311/P+++8TGxvLzz//zLvvvktSUhIrV64kMTGRWrVqufoV3LcbFBTkmg4KCspyjNmvV/ZpYwyvvvqqq89q27ZtXHjhhR7LektiYiKtW7fmjz/+4KWXXuKHH35gzZo19O/f/JUA8AAAGllJREFU32O4/xzlBgzgRESEdQneuTMwxCQjAx5/3OYQiY21QRedPDtK2UCFpJjxJoy8e7h4X9KtWzcmTZpEFydSapcuXbJMZ6eoIdvBvggnTJjA3XffDVjx+uSTTwCbOjhTKLp06cJPP/1ExYoVqVixIu3bt+eNN97IN4nUvffe63pxR0ZGukLDg+0X2bZtGw0bNiQpKYnIyEhCQkKYM2dOllS73vLll19y8uRJDh065Mqa6M7FF1/Mq6++6hKfTZs2kZaWRs+ePfn444/JyMhg9+7dXjkeGGOYOHEihw8fpl+/fhw7dowqVapQtWpV9u7d68phD1mvk8dy1arZiNUHDtiUvf4kKcnmD5kwwXas//ADOF6BStmhTDZOhkeFF7v7r7fkFkZ+3LhxDBs2jPj4eC644AJXuPjsxMbGFsi19PHHH6dbt24e3W27devG5MmTXcKRkJDAzp07ueOOOzxu6+abb+bWW28lLCwsS0bB/Pjxxx+Ji4vj+PHjREVF8eqrr3LBBRcA8MorrzBy5EieeeYZoqKimDZtGmCb2urVq+dqYuvRoweff/6551DqebB8+XJGjRpFhQoVyMjI4M477yQuLo769eszaNAgEhISiI+Pp0WLFgXaLkCHDh0YMGAAO3fu5IknniAqKiqL0N5+++3s2LGD2NhYACIjI/nqq68YOnQoP/74I+3ataNVq1ZZalnZGT16NOPGjXO5//7www9UqFCB+Ph42rRpQ7t27WjatGmWPq3bbruNvn370qBBA+bMmeO5XHS09Yzavdt/2QN//x0uu8wGX5w82br5arysMomGkVf8TiBelzFjxlCrVi3uv/9+f5tSeDIybHbFY8fYEBRE6/h4r1ctchj5mTNh2DArYp9+al18lSKjYeQVRSlZgoKgWTObw+TgQVi61Pf7NAb+/W+45BJo3Nj2h6iIlHnKZNOWohSV0jawMVeCg22GxT177Mt98WI7gNEXHD9u+0E++giuvhreesuGcFHKPFojUZSyToUKNvx8UBBcfLFvws/v2AHdu8PHH9uO9Y8/VhEpR6iQKEp5oEIF+O4728Q1YAAcO1Z8216wwAZd3LLFZjN89FHtVC9nqJAoSnmhQwcbnn3dOhgyBE6eLPo2p0yBCy+02RuXLrXNZ0q5Q4VEUcoT/fvbiLvz5sFNNxU+lMqpU3DHHdal96KLrIice26xmqqUHsqkkNSpY2vW2X9Vq1bxOD+/nzfjp0SEG9xCPqSnp1O7dm0uvfRSj+UbN27sCtkRkU8Cn8GDBxMbG0vz5s2pVq2aa2R3bjGcMjIyqFmzJsec5otdu3YhIq5owMYYzjnnHI4ePcrkyZNdAyWzR/+Njo7m6NGjedo2derUHC6y3bt3L9BYGIAnn3yStm3bEhMTQ1xcXI5wJMVNQW2cO3dujjDwmfOrVatGXFwcLVu25IILLmDGjBn5bu+HH35wXY8SZ8QIePZZ24/x4IMFH/2+f7+thbz2GjzyCHz9NeSRakAp+5RJr61ssfVKZHvuYeTDwsKKPYw8WB/y559/3mN+E3fcw8hfdNFFWcLId+7cOUcY+Uzeeust4uPjXflISorFixcze/ZsVq1aRcWKFTl48KDX4VgCgd69e/Pll18CsHLlSgYPHsy7777rGpTpiR9++IFatWrRuXPnkjIzK//4h/XkmjTJ5kZ/KO98Oy5WrLBpcA8ftt5ZThw1pXxTJmsk/kLDyGclPT2d6tWrM3r0aOLj4+nXrx+HDx/OUW7fvn3Url3bFXG4du3a1K1bF7ARATp06EC7du244447XOete/fuPPDAA/To0YM2bdqwYsUKBg8eTIsWLRg/fjxgQ8a3bduWG264gfbt23P11Ve7wqm4M3PmTLp06UJ8fDzXXHMNqak2KsJ3331Hq1at6N69O1999ZVXx5w9jP5XX31Fp06diIuL46KLLuLAgQNs2bKFqVOn8txzz7lqlp7K+RQRmDjRuun+/e/w/vv5r/PBB9Cjh/X+WrRIRURxoUJSjGgY+ZwkJSXRuXNnVq5cSZcuXfjXv/6Vo0zfvn3ZsmULrVq14u6773ZFCAa47777WL58OWvXriUpKYlZs2a5loWFhbFw4UJGjhzJFVdcwZQpU1i7di2vv/66q0lu/fr13H333axdu5bQ0FBee+21LPs+cOAAzz77LPPmzWPlypXExMTw0ksvcfz4cW6//XZmzJjBwoUL2bNnj9fH7B4KvmfPnvzyyy+sWrWKIUOG8MILL9CsWbP/b+/Mo6yo7jz++dKNtqg0oXE6LIbmgEtYBBHRsESMBtGTYDhCiMEFDaI5GqIZNPHoMESzuJJJ4nAIrpjBjgtg1EkEITSIC4Is3XYrYGhExiSDmhFBNvE3f9xb3dWv33v9mu7XPOz7OeedV3Xr1q1776+q7lJV3x+TJk3ixhtvrHFQlixe1mnTxkm5jxgBV1wB3g9KPQ4ccI3NJZe4B/arVsGpp2Y/f4HDhtCQNCOtUUY+lcptFJ6fn8+4ceMA51p2xYoV9eK2b9+eNWvWMGvWLIqKihg7dmyNy+IlS5YwePBg+vfvz7Jly6isrKzZb/To0YCTf+/Xrx/FxcUUFBRQUlLCtm3bAOjRo0fN9FGy47/88stUVVUxZMgQBgwYwNy5c9myZQtVVVWceOKJ9OzZE0k1XiQzIT7a3Lp1KyNHjqRfv37MmDGjTv7jZBqv2TnySHj6aejdGy66CF5/ve72f/7TvYl1zz3uwfrixe6blEAgRmhImpnWJiNfVFRUT8n4ww8/pFOnTkByKfYtW7bUvDAQeRXMz8/n7LPP5rbbbuPXv/418+fP55NPPuG6665jwYIFlJeXc+WVV9aRUo/LvydKw0d5zUQKftSoUTWKwlVVVcyePTtp3EyJy+hfe+213HDDDVRUVDBz5sykUvCNiZcVCgudNlbHjnDBBe57EICqKhg82Cn2zp4NM2eCH6kGAnFCQ9LMtDYZ+TPOOIPly5fXzOmvXLkSM6NLly4A7N+/n/nz5wPw2GOPMWzYMEpKSmpu3JMmTWLDhg28/fbbNWmuX7+e7t27s3v3btq0aUOnTp34+OOPmTdvXqProLq6uuYNsNLSUoYNG1Zn+5AhQ1i2bBmbN28GYNeuXWzatInevXuzceNGqqurMTNKS0szOl6ijP5HH31E165dMTPmzJlTEy+xrlPFazG6dIGFC53TqfPOo/j55+HMM92Hi0uXwlVXtXyeAocNn8uGpLj40KWXTkZ++fLlDBw4kEWLFqWVkW8Mt9xyS8rXTYcOHcrmzZvrycinmtaKZOTjD9sbonPnztx7772cd955DBgwgKlTp1JaWlrTmy8sLGTNmjUMHDiQFStWcOutt9ZLY+fOnVx66aX07t2bfv36sWnTJqZNm0ZRURGXX345ffv2ZcyYMXWeOWVKnz59uP/++znllFPYtWsXkydPrrO9uLiYBx98kPHjx9O/f3+GDBnCxo0badeuHbNmzeL8889n+PDhNT7mkxHJ6J900klMmTKljoz+9OnTGTNmDGeddRbFsRPpwgsv5Iknnqh5my5VvBbl5JPhuefgvff48p13Ok2u1audV8NAIB1mlrUfMArYALwN/CTJ9onAdmCd/01qKM3TTjvNEqmqqqoXlowdO3ZkFC/QPOzfv98KCwsbjJctu2zatMn69++flbQPNzK9RszMbPFi2zJhgtknn2QvQ4GDYunSpQe9L7DasnSvz9p3JJLygP8Evg5sA1ZJesbMEh1PP25m12UrH4FAoJGccw7VeXl0P+qoQ52TwGFCNqe2BgNvm9lmM9sH/AG4MIvHC+QY+fn5DX4Zn0169erV6C/sA4FA48nml+1dgXdj69uAZJPcF0n6KrARuMHM3k2MIGkyMBncnHZZWVmd7YWFhezYsaPBt2wOHDjQZJ/kgeYn2CW7mBl79uypd92kY+fOnY2KH2gZctUu2WxIkt3VEz/nfhYoNbO9kq4B5gBfq7eT2WxgNjhXu4muJqurq9m3bx9FRUVpG5NcdOkaCHbJJmbGBx98QIcOHTi1ER8RNtnVbiAr5KpdstmQbAOOj613A+p8Hmxmcb2M+4E7D+ZA3bp1Y9u2bWzfvj1tvD179lBQUHAwhwhkkWCX7FJQUEC3bt0OdTYCn2Oy2ZCsAk6Q1AP4H+A7wHfjESR1NrPIXdto4M2DOVDbtm3p0aNHg/HKysoa1SsLtAzBLoHA4U3WGhIz+1TSdcBCIA94yMwqJd2Gew3tGWCKpNHAp8CHuNeBA4FAIHAYkVUZeTP7E/CnhLBpseWbgZuzmYdAIBAIZJfP5ZftgUAgEGg5ZFn2i9HcSNoOvHOQu3cC3m/G7ASah2CX3CPYJDdpil26m9lxzZmZiMOuIWkKklab2aBDnY9AXYJdco9gk9wkV+0SprYCgUAg0CRCQxIIBAKBJtHaGpLZhzoDgaQEu+QewSa5SU7apVU9IwkEAoFA89PaRiSBQCAQaGZCQxIIBAKBJpHVhkTSGEkm6eRsHidbSLpFUqWkcknrJDXe12uOIemAL8sbkp6U1K4Z0hwk6TdptneR9FRTj+PT+oaktZLWS6qSdHVzpJurJNjrWUkdmjn9iZLu88vTJU1NEuckSWU+H29Kysl5+pYiZpPoV5IkziOSqv32tyT9ewbpTpTUpZF5yQnbZFUiBbgYWIETbJyerYNIyjOzA82c5leAbwADvcx9J+CIJqaZb2afNksGD57dZjbA52cucA0wI9oop8MvM/ss0wTNbDWwOs3294CxB53j2ry1xT1sHGxm2yQdCZQ0Mc1Gl7eFidtrDnAt8PMWzsNvgF+Z2R99Pvo1NcFsXLMtSI1NGuBGM3tKUgFQJelRM6tOE38i8AYJKukNkBO2ydqIRNIxwFDge7iGJL7tJkkVvld5hw/rJWmxD1sjqaekEZKei+13n6SJfnmLpGmSVgDjJF0laZXff17U05ZULGmBD18vaYik2yX9MJbuzyVNSShCZ+B9M9sLYGbv+xsikk6X9LJP7zVJx0oqkPSwL9daSWf7uBN9z/9ZYJEPu9HntVzST5uv1hvNi0AvSSW+NzMTWAMcL2mkpFe8LZ709kxV9ho7STor1lNb67eXSHrDb09XT/MlPS9pk6S7kuT3WFzn5wMAM9trZhv8/vXs7MN/JNebf0PS9T4s4/LmGK/gHMYBqc8jSZf5sPWSfu/Dvilppa/zxZKKG3Hczji3EACYWYVPM0/SPd6W5ZJ+4MPP8cepkPSQXIOf7Jrt6e39uqQXdZjOXGRA5CNhF4Ck0yQt8+VeKKmzpLHAIGCuv3aO8nW1yp+7s6WkzpZywzbZcgYPXAI86JdfxvXsAc736+38ekf/vxIY45cLgHbACOC5WJr3ARP98hbgpti2otjyz4Af+OXHgev9ch5QiOvFrvFhbYC/xvf34ccA63CeG2cCZ/nwI4DNwOl+vT3u5vavwMM+7GRgqy/HRG/oqJwjcb1q+WM/B3w1W3ZIYped/j8f+CPwfV8fnwFn+m2dgOXA0X79x8C0NGWvsRPOWdnQWB3m+/Tf8GHp6mmzt08BTgbn+CT5fwD4X6AUmAC0SWPn04AK4Gifl0rg1EzL21I2ydBeecCTwKh05xHQB9gAdEq4vr5A7Vuak4B7/fJE4D6/PB2YmiQPVwAfAX8GbgA6+PDvA/OA/OhY3nbvAif6sEdjdtlC3Wt2CXCCXz4D+Muhru8MbXIAd29YByxIEecRoNrH2Qn8woe3xd3/jvPr43HK6ABlwKBYGh1jy78Hvpmrtsnm1NbFwH/45T/49TXAubgbyScAZvahpGOBrma2wIftARp0nYu7eUT0lfQzoAPuprHQh38NuMynewBX6R9J+kDSqUAxsNbqOtnCzHZKOg0YDpwNPC7pJ8DrwN/MbJWPt8PndRjwWx/2lqR3gBN9ci+Y2Yd+eaT/rfXrxwAn4G5kLcFRkiJH5i8CDwJdgHfM7FUffibQG3jJ2+AIXG/4JJKXPZ7+S8AMuWmz+eamoOLb09XTEjP7yKdZBXSnrrtmzGyS3PD9XGAq8HXczbCenb1NFphZ1BOcj7PnMxmWNxeI7FWCO/de8OGpzqP+wFNm9j6468tv74Y7hzvjypduiqUOZvawpIXAKOBC4GpJ/XE2mGV+utZfy/2BajPb6HePpuOie8HjUDNjMQR4MnZ+HJlpng4xjZ3aOgZY4kfJO4C+wAu+3HnA31Lsf7akm3Cd6o64jtCz8Qi5YpusNCSSinAXdl9Jhqss85Ui6rvcTdVifErd6bdEN3q7YsuPAN8ys/Vy018jGsjmA7gb0BeBh5JF8DekMqBMUgVwOa4xTPbxTbpWL55PAb80s981kL9sUe8i8CdLYh5fMLOLE+KdQvKy12Bmd0j6b+AC4FVJ5wJ7EtJOxd7Y8gFSnJ/mhu8VftqmmtR+bBpjk3rlzRF2m9kASYW4Uce1uHnxpOeR3BRtMhv9FphhZs9IGkEjn1mam9Z9CHhIbpqyL427liOiem8D/F+GN+ScR9LDuNHue2Z2QXyb75SW4TpRfwYqzewrDaRXgJsJGWRm70qaTv37X5T+IbdNtp6RjAUeNbPuZlZiZsfjLvhhuOcEV6r2GUZH37PdJulbPuxIv/0doLdfLwTOSXPMY4G/yT2QnRALX4Ib5kXzhu19+AJcK346taOXGuTehjghFjTA5+ctoIuk0328YyXl40YUE3zYicCXcFMMiSz05Y+eOXSV9C9pynUoeBUYKqkXgKR2vkypyl6DpJ5mVmFmd+IewCfOrWZaT/WQdIy/CUZENoHkdl4OfMvn/2hgDG4Ulml5cwY/UpsCTPXneKrzaAnwbd+ZQ1JHn0QhzlMpuA5Rxkga5Y+JpC8CRT6tRcA10Tngj/UWUBLVJXApsCxJeXYA1ZLG+X3le8yHJWZ2hZkNSGxEwL1kg5se+ivuXD9O7mUeJLWV1MdH/Rh3H4PaRuN9b+OkL6vkim2y1ZBcjLtRx5kHfNfMnsdNLaz2Q/bodcNLcR4Ty3FziF80s3eBJ4ByYC61w/hk/BvuOcsLuAqL+CFuiFiBmxroA2Bm+4ClwBOW/A2FY4A5cq+YluOmPqb7/cYDv5W03h8v6j3k+eM8jnuWszcxUTNbBDwGvOLjPkXtyZMTmNl2XC+/1Jf9VeDkNGWPc73cw8H1wG5cDyxORvWUAgE3Sdrgz52fUjsaqWdnM1uDG6m+hjs3HjCzeudQqvJmmKcWw+d9PfCdVOeRmVXi3upa5m0QvZE3HTdV8SKNlyEfCUQ2XYibsvk7blS/FSj3277rp6Wv8MeqwD2LmpUi3QnA9/y+lbipmc8Td/vztBz3rG6+v4bGAnf6cq/DTSOBO1dn+X32Avf7/Z7GuS5PRk7YptVKpEhqg5umGmdmmw51fgKBQOBwpVV+2S6pN/A27uFuaEQCgUCgCbTaEUkgEAgEmodWOSIJBAKBQPMRGpJAIBAINInQkAQCgUCgSYSGJJAV1ESVYUnD5ZSX10k6Klv5zDZyul4m6fZYWCdJ++VVd9PsO0JeMyzF9tFyaguZ5GOlr8utkrYrjXJtINBYQkMSyBa7/QdafYF9OJXhjJCUh3uP/R6fxu4M98lVNuOUpCPG4d7Nb4gR1H5jUAc5JelnzOyOTDJgZmf4L5WnAY/7eh1gZlsy2T8QSEdoSAItwYtA9NX4JXKqwesk/S5qACTtlHSbpJXAzcC3gWmS5vova+/2o5sKSeP9PiMkLZX0GE4ypUTO98MDPu5cSedKeklOUXiw32+wnILxWv9/kg9PqUDsvyBeI6eou8SHHS2noLrKp5Xqo63dwJuSBvn18bgPbaO0j5NTrF7lf0P9SOEa4AZfV8PlfFzMkLQU90HbRNX6EkmqftwQkq6WdHds/fuS7pJT466U9Htf509EI0M5Behlcsqwf1bjlIQDn0fSKTqGX/gd7I/kKsNfxonOtfXbZgKX+WUDvh3b/xFgrF++CPcVfR5OZHMrTj57BE4fqIePV4LTZ+uH6yS9jtMgEu7L3Kd9vPbUqqKeC8zzyxNJokAMHIcTj4yOEynq/gK4xC93wClFH51QDyU4HxOjgXtw4olLqKu6+xgwzC9/CXjTL08npsbr6+Q5IC+W3yiNeurHKexSs49fPxYn3RHVx2s4FYde3iaRQvKjwPU48b6XqVUXngDMPtTnW/gd2l+2HVsFWi/JVIYn46TdV8kJRR6Fk4QHJ9I4L0Vaw4BSc1I2/5C0DKeRtgN4zeo6C6q2Wp8MlbiPTs1LQpT4OIU4+ZsTcDfLtrH9kykQfwFYHh3H6io5j1atV8ECfEOQpAzPA7cD/6CuajW4xqy3apVW28spYifjSUsu6ZNM5bpBzOxjScuB8yVtBg6YWZWcHlO11Sok/xfOfmU4maHFqlWv3VY/5UBrIjQkgWyRTGVYwBwzuzlJ/D0pbpCQuYov1FUQ/iy2/hm15/vtwFIzG+OnkMpS7B8pECdTUo3ydZF551rpMLN9kl7H+WPpA3wztrkN8BVLeBak5G4UEsvbHDwA/Ajnk+LhWHhimQ1X5nIzG56FfAQOU8IzkkBLsgQYK692LKmjpO4Z7LccGC+n6nsczoHTa03IR1wJd2IG8V8BzpLUA+oo6i4EfuAbSOT826TjXuDHluD7BqfUel20IilqgONqsA2RSuW6QczsJaAn7iWA+Giph7zSM7Vus6uArrHnTUeoVr020EoJDUmgxTCzKuBWYJGcyu4LuGcdDbEAp6C6HvgLzpPb35uQlbuAX0p6CTc1kxZz6sCTgflyaqjRzfZ23LRYuZwfiNtTJBGlU2lmc5JsmgIMknOJWkXtG27PAmOih+0NZDOpynUjeAo3fRefEqsErvK2Ohr3LGQvTr12hq+LtTiJ9EArJmhtBQIBJD2Pc5S1zK/3wnla/Fw4ngpklzAiCQRaMZKKJG0E/hk1IoFAYwkjkkAgEAg0iTAiCQQCgUCTCA1JIBAIBJpEaEgCgUAg0CRCQxIIBAKBJhEakkAgEAg0if8HZMDah08PEAsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "x_labels = ['Accuracy Score', 'Precision Score', 'Recall Score', 'F-Beta Score (=0.50)']\n",
    "\n",
    "y_units_raw_data = [accuracy_score(y_test, predictions),\n",
    "                   precision_score(y_test, predictions),\n",
    "                   recall_score(y_test, predictions),\n",
    "                   fbeta_score(y_test, predictions, beta=0.5)]\n",
    "\n",
    "y_units_down_sampled = [accuracy_score(y_test_down_sampled, predictions_down_sampled),\n",
    "                       precision_score(y_test_down_sampled, predictions_down_sampled),\n",
    "                       recall_score(y_test_down_sampled, predictions_down_sampled),\n",
    "                       fbeta_score(y_test_down_sampled, predictions_down_sampled, beta=0.5)]\n",
    "\n",
    "y_units_up_sampled = [accuracy_score(y_test_up_sampled, predictions_up_sampled), \n",
    "                   precision_score(y_test_up_sampled, predictions_up_sampled),\n",
    "                   recall_score(y_test_up_sampled, predictions_up_sampled),\n",
    "                   fbeta_score(y_test_up_sampled, predictions_up_sampled, beta=0.5)]\n",
    "\n",
    "\n",
    "plt.title('Performance Metrics according to Data Resampling')\n",
    "plt.xlabel('Performance Metric Type')\n",
    "plt.ylabel('Performance Value')\n",
    "\n",
    "plt.plot(y_units_raw_data, color='red')\n",
    "plt.plot(y_units_down_sampled, color='purple')\n",
    "plt.plot(y_units_up_sampled, color='blue')\n",
    "\n",
    "raw_data_patch = mpatches.Patch(color='red', label='Model Trained With Raw Data')\n",
    "down_sampled_patch = mpatches.Patch(color='purple', label='Mdl. T. With Down-Sampled Data')\n",
    "up_sampled_patch = mpatches.Patch(color='blue', label='Mdl. T. With Up-Sampled Data')\n",
    "plt.legend(handles=[raw_data_patch, down_sampled_patch, up_sampled_patch])\n",
    "\n",
    "x_labels = ['Accuracy Score', 'Precision Score', 'Recall Score', 'F-Beta Score']\n",
    "\n",
    "#plt.xticks(range(0, len(x_labels)), x_labels.index)\n",
    "plt.xticks(np.arange(len(x_labels)), x_labels)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
